{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "git_repo = '../../../../'\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "\n",
    "sys.path.insert(0, os.path.join(git_repo, 'BNP_sensitivity/GMM_clustering/'))\n",
    "sys.path.insert(0, '../../../../LinearResponseVariationalBayes.py/')\n",
    "\n",
    "# Linear response libraries\n",
    "import LinearResponseVariationalBayes as vb\n",
    "import LinearResponseVariationalBayes.SparseObjectives as obj_lib\n",
    "import LinearResponseVariationalBayes.OptimizationUtils as opt_lib\n",
    "import LinearResponseVariationalBayes.ModelSensitivity as model_sens\n",
    "\n",
    "# Local libraries\n",
    "import gmm_clustering_lib as gmm_utils\n",
    "import modeling_lib\n",
    "import functional_sensitivity_lib as fun_sens_lib \n",
    "import utils_lib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from autograd import numpy as np\n",
    "from autograd import scipy as sp\n",
    "\n",
    "# import numpy as np\n",
    "# import scipy as sp\n",
    "\n",
    "np.random.seed(453453)\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_dir = './iris_fits_for_nips/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_input_file = os.path.join(fit_dir, 'bnp_full_data_fit_alpha3.0_iris.json')\n",
    "\n",
    "with open(json_input_file, 'r') as fp:\n",
    "    fit_dict = json.load(fp)\n",
    "    model = gmm_utils.get_model_from_checkpoint(fit_dict)\n",
    "    model_ = gmm_utils.get_model_from_checkpoint(fit_dict)\n",
    "    best_param = model.global_vb_params.get_free()\n",
    "    kl_hessian = gmm_utils.get_kl_hessian_from_checkpoint(fit_dict)\n",
    "    prior_param_vec0 = model.prior_params.get_vector()\n",
    "    \n",
    "#moment_model = gmm_utils.InterestingMoments(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.]\n"
     ]
    }
   ],
   "source": [
    "alpha0 = model.prior_params['alpha'].get()\n",
    "print(alpha0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up linear sensitivity class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this is analagous to the moment model, but for expected number of clusters\n",
    "# e_num_clusters_class = gmm_utils.ExpectedNumClustersFromZ(model)\n",
    "# e_num_clusters_class.set_e_num_clusters_from_free_param(best_param)\n",
    "\n",
    "# linear_sensitivity = \\\n",
    "#     obj_lib.ParametricSensitivity(\\\n",
    "#         objective_fun =             model.set_z_get_kl,\\\n",
    "#         input_par =                 model.global_vb_params,\\\n",
    "#         output_par =                e_num_clusters_class.e_num_clusters,\\\n",
    "#         hyper_par =                 model.prior_params,\\\n",
    "#         input_to_output_converter = e_num_clusters_class.set_e_num_clusters,\\\n",
    "#         optimal_input_par =         best_param,\\\n",
    "#         objective_hessian =         kl_hessian)\n",
    "\n",
    "\n",
    "linear_sensitivity = \\\n",
    "    model_sens.ParametricSensitivityLinearApproximation(\\\n",
    "        objective_functor =         model.set_z_get_kl,\\\n",
    "        input_par =                 model.global_vb_params,\\\n",
    "        hyper_par =                 model.prior_params,\\\n",
    "        input_val0 = best_param, \n",
    "        hyper_val0 = prior_param_vec0, \n",
    "        hess0 = kl_hessian)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load refitted models and get linear approximations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Get the expected posterior predictive number of distinct clusters.\n",
    "# def get_e_num_pred_clusters_from_free_par(free_par, model):\n",
    "#     model.global_vb_params.set_free(free_par)\n",
    "#     mu = model.global_vb_params['v_sticks']['mean'].get()\n",
    "#     sigma = 1 / np.sqrt(model.global_vb_params['v_sticks']['info'].get())\n",
    "#     n_obs = model.n_obs\n",
    "#     return modeling_lib.get_e_number_clusters_from_logit_sticks(mu, sigma, n_obs)\n",
    "\n",
    "# # Get the expected posterior number of distinct clusters.\n",
    "# def get_e_num_clusters_from_free_par(free_par, model):\n",
    "#     model.global_vb_params.set_free(free_par)\n",
    "#     model.set_optimal_z()\n",
    "#     return modeling_lib.get_e_number_clusters_from_ez(model.e_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = glob.glob(fit_dir +  '/bnp_full_data_fit_alpha*_iris.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e_num_heavy_clusters_class = gmm_utils.ExpectedNumClustersFromZ(model)\n",
    "e_num_pred_heavy_clusters_class = gmm_utils.ExpectedPredNumClusters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./iris_fits_for_nips/bnp_full_data_fit_alpha9.5_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha1.5_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha15.0_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha13.0_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha12.0_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha0.5_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha5.0_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha12.5_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha7.0_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha3.0_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha5.5_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha10.0_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha2.0_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha14.5_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha8.5_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha3.5_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha7.5_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha11.5_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha4.0_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha2.5_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha15.5_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha9.0_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha11.0_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha4.5_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha8.0_iris.json\n",
      "./iris_fits_for_nips/bnp_full_data_fit_alpha10.5_iris.json\n"
     ]
    }
   ],
   "source": [
    "free_par_refit_list = []\n",
    "free_par_lr_list = []\n",
    "\n",
    "e_num_clusters_lr_list = []\n",
    "e_num_clusters_refit_list = []\n",
    "\n",
    "e_num_pred_clusters_lr_list = []\n",
    "e_num_pred_clusters_refit_list = []\n",
    "\n",
    "alpha_vec = np.zeros(len(files))\n",
    "\n",
    "for i in range(len(files)):\n",
    "    print(files[i])\n",
    "    \n",
    "    # load perturbed model \n",
    "    #json_input_file = os.path.join(fit_dir, files[i])\n",
    "    json_input_file = os.path.join(files[i])\n",
    "\n",
    "    with open(json_input_file, 'r') as fp:\n",
    "        fit_dict = json.load(fp)\n",
    "        model_refit = gmm_utils.get_model_from_checkpoint(fit_dict)\n",
    "    \n",
    "    # prior parameters from refitted model\n",
    "    alpha_vec[i] = model_refit.prior_params['alpha'].get()\n",
    "    prior_param_vec_pert = model_refit.prior_params.get_vector() \n",
    "\n",
    "    # get free parameters from the refitted model \n",
    "    free_par_refit = model_refit.global_vb_params.get_free()\n",
    "    free_par_refit_list.append(free_par_refit)\n",
    "    \n",
    "    # linear approximation for free params\n",
    "    free_par_lr = linear_sensitivity.predict_input_par_from_hyperparameters(\n",
    "        prior_param_vec_pert) \n",
    "    free_par_lr_list.append(free_par_lr)\n",
    "    \n",
    "    # linear approximation for num clusters\n",
    "    #out_par_lr = linear_sensitivity.predict_output_par_from_hyperparameters(prior_param_vec_pert, linear = False)\n",
    "#     e_num_pred_clusters_lr_list.append(\n",
    "#         gmm_utils.get_e_num_pred_clusters_from_free_par(\n",
    "#             free_par_lr, model_refit))\n",
    "#     e_num_pred_clusters_refit_list.append(\n",
    "#         gmm_utils.get_e_num_pred_clusters_from_free_par(\n",
    "#             free_par_refit, model_refit))\n",
    "\n",
    "#     e_num_clusters_lr_list.append(\n",
    "#         gmm_utils.get_e_num_clusters_from_free_par(\n",
    "#             free_par_lr, model_refit))\n",
    "#     e_num_clusters_refit_list.append(\n",
    "#         gmm_utils.get_e_num_clusters_from_free_par(\n",
    "#             free_par_refit, model_refit))\n",
    "\n",
    "    e_num_pred_clusters_lr_list.append(\n",
    "        e_num_pred_heavy_clusters_class.get_e_num_pred_heavy_clusters_from_free_par(\n",
    "            free_par_lr, threshold = 1 / 50))\n",
    "    e_num_pred_clusters_refit_list.append(\n",
    "        e_num_pred_heavy_clusters_class.get_e_num_pred_heavy_clusters_from_free_par(\n",
    "            free_par_refit, threshold = 1 / 50))\n",
    "\n",
    "    e_num_clusters_lr_list.append(\n",
    "        e_num_heavy_clusters_class.get_e_num_heavy_clusters_from_free_par(\n",
    "            free_par_lr, threshold = 1 / 50)[0])\n",
    "    e_num_clusters_refit_list.append(\n",
    "        e_num_heavy_clusters_class.get_e_num_heavy_clusters_from_free_par(\n",
    "            free_par_refit, threshold = 1 / 50)[0])\n",
    "\n",
    "    #out_par_lr_list.append(out_par_lr)\n",
    "    \n",
    "    # refitted num clusters\n",
    "    #model_refit.set_optimal_z()\n",
    "    #out_par_refit = modeling_lib.get_e_number_clusters_from_ez(model_refit.e_z)\n",
    "    #out_par_refit = modeling_lib.get_e_number_clusters_from_logit_sticks(model_refit)\n",
    "    #out_par_refit_list.append(out_par_refit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the free parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i in range(len(free_par_refit_list)): \n",
    "#     plt.figure()\n",
    "#     plt.plot(free_par_lr_list[i]- best_param, free_par_refit_list[i] - best_param, '+')\n",
    "#     plt.plot(free_par_lr_list[i]- best_param, free_par_lr_list[i]- best_param, '-')\n",
    "#     plt.title('alpha = {}'.format(alpha_vec[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.global_vb_params.set_free(best_param)\n",
    "model.set_optimal_z()\n",
    "\n",
    "print(np.sum(model.e_z, axis=0) / model.n_obs)\n",
    "print(gmm_utils.get_e_num_clusters_from_free_par(best_param, model_refit))\n",
    "\n",
    "e_z = model.e_z\n",
    "k = np.shape(e_z)[1]\n",
    "print(k - np.sum(np.prod(1 - e_z, axis = 0)))\n",
    "\n",
    "print(k)\n",
    "print(np.prod(1 - e_z, axis = 0).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results on expected number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(alpha_vec, e_num_clusters_lr_list, '+')\n",
    "plt.plot(alpha_vec, e_num_clusters_refit_list, 'x')\n",
    "\n",
    "plt.axvline(x=alpha0, linestyle = '--', color = 'red')\n",
    "\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('expected number of clusters')\n",
    "\n",
    "plt.legend(('lr', 'refit'))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(alpha_vec, e_num_pred_clusters_lr_list, '+')\n",
    "plt.plot(alpha_vec, e_num_pred_clusters_refit_list, 'x')\n",
    "\n",
    "plt.axvline(x=alpha0, linestyle = '--', color = 'red')\n",
    "\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('expected number of clusters')\n",
    "\n",
    "plt.legend(('lr', 'refit'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save('../../../writing/NIPS_2018_BNP_workshop/data_for_figures/alpha_vec', alpha_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('../../../writing/NIPS_2018_BNP_workshop/data_for_figures/e_num_clusters_thresh3_lr_alpha3', \n",
    "        e_num_clusters_lr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('../../../writing/NIPS_2018_BNP_workshop/data_for_figures/e_num_clusters_thresh3_refit_alpha3', \n",
    "        e_num_clusters_refit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
