{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rliu/anaconda3/envs/bnp_sensitivity/lib/python3.8/site-packages/autograd/core.py:290: UserWarning: \n",
      "The defvjp method is deprecated. See the update guide and tutorial:\n",
      "https://github.com/HIPS/autograd/blob/master/docs/updateguide.md\n",
      "https://github.com/HIPS/autograd/blob/master/docs/tutorial.md\n",
      "  warnings.warn(deprecation_msg)\n"
     ]
    }
   ],
   "source": [
    "import autograd\n",
    "\n",
    "import autograd.numpy as np\n",
    "\n",
    "import autograd.scipy as sp\n",
    "\n",
    "from bnpmodeling_runjingdev.modeling_lib import my_slogdet3d\n",
    "\n",
    "import bnpgmm_runjingdev.gmm_clustering_lib as gmm_lib\n",
    "import bnpgmm_runjingdev.gmm_preconditioner_lib as precond_lib\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import paragami\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check log-partition function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.random.randn(dim)\n",
    "info = np.random.randn(dim, dim)\n",
    "info = np.dot(info, info.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get paragami objects\n",
    "mvn_params_paragami, mvn_nat_params_paragami = \\\n",
    "    precond_lib.get_mvn_paragami_objects(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of parameters\n",
    "mvn_params_dict = mvn_params_paragami.random()\n",
    "mvn_params_dict['mean'] = mean\n",
    "mvn_params_dict['info'] = info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector of free canonical parameters\n",
    "mvn_free_params = mvn_params_paragami.flatten(mvn_params_dict, free = True)\n",
    "\n",
    "# vector of natural parameters\n",
    "nat_vec = precond_lib.get_nat_vec(mvn_free_params, mvn_params_paragami, mvn_nat_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.006251974847423"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precond_lib.get_mvn_log_partition(nat_vec, mvn_nat_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get gradient of log partition function\n",
    "get_grad_log_part = autograd.grad(precond_lib.get_mvn_log_partition)\n",
    "grad_log_part = get_grad_log_part(nat_vec, mvn_nat_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold gradient into dictionary\n",
    "grad_log_part_folded = mvn_params_paragami.fold(grad_log_part, free = False, validate_value = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get expectations of sufficient statistics\n",
    "e_x = mean\n",
    "e_x2 = np.linalg.inv(info) + np.einsum('i, j -> ij', mean, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.217248937900877e-15"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check they match with gradient of log partition\n",
    "np.abs(e_x - grad_log_part_folded['mean']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3803181647963356e-13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(-e_x2 - grad_log_part_folded['info']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Fisher information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fishers_info = precond_lib.get_fishers_info(mvn_free_params, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a slightly different way to get the fishers info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dA / deta, eta being the natural pameters\n",
    "get_dA_deta = autograd.grad(precond_lib.get_mvn_log_partition)\n",
    "dA_deta = get_dA_deta(nat_vec, mvn_nat_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_partition_free_canon(mvn_free_param, mvn_params_paragami, mvn_nat_params_paragami): \n",
    "    # this is A(eta(theta)), where eta(theta) is the natural parameters as a function of the \n",
    "    # free canonical parameters \n",
    "    \n",
    "    nat_vec = precond_lib.get_nat_vec(mvn_free_param, mvn_params_paragami, mvn_nat_params_paragami)\n",
    "    return precond_lib.get_mvn_log_partition(nat_vec, mvn_nat_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dA2_dtheta2 = autograd.hessian(get_log_partition_free_canon)\n",
    "dA2_dtheta2 = get_dA2_dtheta2(mvn_free_params, mvn_params_paragami, mvn_nat_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is d^2 eta / dtheta^2\n",
    "get_deta2_dtheta2 = autograd.jacobian(precond_lib.get_jac_term, 0)\n",
    "deta2_dtheta2 = get_deta2_dtheta2(mvn_free_params, mvn_params_paragami, mvn_nat_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively the fishers info can be computed as \n",
    "# d^2A/dtheta^2 - dA/deta d^2eta / dtheta^2\n",
    "fishers_info2 = dA2_dtheta2 - np.einsum('j, jik -> ik', dA_deta, deta2_dtheta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.353672812205332e-13"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(fishers_info - fishers_info2).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We also check against sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normal_logpdf(x, mean, info): \n",
    "    assert x.shape[1] == len(mean)\n",
    "    assert info.shape[0] == len(mean)\n",
    "    \n",
    "    diff = x - mean[None, :]\n",
    "    \n",
    "    cross = np.einsum('ni, ij -> nj', diff, info)\n",
    "    squared = np.einsum('nj, nj -> n', diff, cross)\n",
    "    \n",
    "    return -0.5 * squared + 0.5 * np.linalg.slogdet(info)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_q(x, mvn_free_params, mvn_params_paragami): \n",
    "    mvn_params_dict = mvn_params_paragami.fold(mvn_free_params, free = True)\n",
    "    \n",
    "    mean = mvn_params_dict['mean']\n",
    "    info = mvn_params_dict['info']\n",
    "    \n",
    "    return get_normal_logpdf(x, mean, info).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.multivariate_normal(mean, np.linalg.inv(info), 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.32855682941957165"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_log_q(x, mvn_free_params, mvn_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_est_fishers_info = autograd.hessian(get_log_q, argnum = 1)\n",
    "est_fishers_info = - get_est_fishers_info(x, mvn_free_params, mvn_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04769416103364321"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(fishers_info - est_fishers_info).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yet another way to get the fisher's info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_score_fun = autograd.grad(get_log_q, argnum = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "score_fun2_all = np.zeros((n_samples, len(mvn_free_params), len(mvn_free_params)))\n",
    "for i in range(n_samples): \n",
    "    score_fun = get_score_fun(x[i:(i+1)], mvn_free_params, mvn_params_paragami)\n",
    "    score_fun2_all[i] = np.einsum('i, j -> ij', score_fun, score_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_score_fun2 = score_fun2_all.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sd_score_fun2 = score_fun2_all.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "zscores = ((fishers_info - mean_score_fun2) / (sd_score_fun2 / np.sqrt(n_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(zscores.flatten(), bins = 100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OK, now we do it for the full set of vb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vb parameters\n",
    "k_approx = 30\n",
    "vb_params_dict, vb_params_paragami = gmm_lib.get_vb_params_paragami_object(dim, k_approx)\n",
    "vb_params_dict = vb_params_paragami.random()\n",
    "\n",
    "vb_free_params = vb_params_paragami.flatten(vb_params_dict, free = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "preconditioner = precond_lib.get_gmm_preconditioner(vb_free_params, vb_params_paragami).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fishers_info = np.linalg.inv(preconditioner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check cluster parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(k_approx):\n",
    "    bool_dict = vb_params_paragami.empty_bool(False)\n",
    "    bool_dict['cluster_params']['centroids'][:, k] = True\n",
    "    bool_dict['cluster_params']['cluster_info'][k] = True\n",
    "\n",
    "    # get indices\n",
    "    indx_cluster_params_k = vb_params_paragami.flat_indices(bool_dict, free = True)\n",
    "    \n",
    "    # get free parameters for this cluster\n",
    "    mvn_params_dict['mean'] = vb_params_dict['cluster_params']['centroids'][:, k]\n",
    "    mvn_params_dict['info'] = vb_params_dict['cluster_params']['cluster_info'][k]\n",
    "    mvn_free_params_k = mvn_params_paragami.flatten(mvn_params_dict, free = True)\n",
    "    \n",
    "    assert (mvn_free_params_k == vb_free_params[indx_cluster_params_k]).all()\n",
    "    \n",
    "    # get fisher's info \n",
    "    fishers_info_k = precond_lib.get_fishers_info(mvn_free_params_k, dim)\n",
    "    \n",
    "    # compare with giant fisher's info matrix\n",
    "    for i in range(len(indx_cluster_params_k)): \n",
    "        for j in range(len(indx_cluster_params_k)): \n",
    "            assert np.abs(fishers_info[indx_cluster_params_k[i], indx_cluster_params_k[j]] - \n",
    "                          fishers_info_k[i, j]).max() < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_manual_fishers_info(free_params): \n",
    "    assert len(free_params) == 2\n",
    "    return np.array([[np.exp(free_params[1]), 0], [0, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(k_approx - 1):\n",
    "    bool_dict = vb_params_paragami.empty_bool(False)\n",
    "    bool_dict['stick_params']['stick_propn_mean'][k] = True\n",
    "    bool_dict['stick_params']['stick_propn_info'][k] = True\n",
    "\n",
    "    # get indices\n",
    "    indx_cluster_params_k = vb_params_paragami.flat_indices(bool_dict, free = True)\n",
    "    \n",
    "    fishers_info_k = get_manual_fishers_info(vb_free_params[indx_cluster_params_k])\n",
    "    \n",
    "    # compare with giant fisher's info matrix\n",
    "    for i in range(len(indx_cluster_params_k)): \n",
    "        for j in range(len(indx_cluster_params_k)): \n",
    "            assert np.abs(fishers_info[indx_cluster_params_k[i], indx_cluster_params_k[j]] - \n",
    "                          fishers_info_k[i, j]).max() < 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnp_sensitivity",
   "language": "python",
   "name": "bnp_sensitivity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
