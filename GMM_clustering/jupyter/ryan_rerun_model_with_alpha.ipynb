{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_repo = '../../..'\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.join(git_repo, 'BNP_sensitivity/GMM_clustering/'))\n",
    "\n",
    "# Linear response libraries\n",
    "import LinearResponseVariationalBayes as vb\n",
    "import LinearResponseVariationalBayes.SparseObjectives as obj_lib\n",
    "\n",
    "# Local libraries\n",
    "import gmm_clustering_lib as gmm_utils\n",
    "import modeling_lib \n",
    "import functional_sensitivity_lib as fun_sens_lib \n",
    "import utils_lib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "np.random.seed(453453)\n",
    "\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load results from previous fit.\n",
    "base_filename = 'ryan_iris_bnp_full_data_fit_alpha8.0.json'\n",
    "json_input_file = os.path.join(\n",
    "    git_repo, 'BNP_sensitivity/GMM_clustering/iris_fits/', base_filename)\n",
    "\n",
    "with open(json_input_file, 'r') as fp:\n",
    "    fit_dict = json.load(fp)\n",
    "    model = gmm_utils.get_model_from_checkpoint(fit_dict)\n",
    "    model_ = gmm_utils.get_model_from_checkpoint(fit_dict)\n",
    "    best_param = model.global_vb_params.get_free()\n",
    "    kl_hessian = gmm_utils.get_kl_hessian_from_checkpoint(fit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Hessian...\n",
      "Data Hessian...\n",
      "Linear systems...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "moment_model = gmm_utils.InterestingMoments(model)\n",
    "dg_deta = moment_model.get_moment_jacobian(best_param)\n",
    "linear_sens = gmm_utils.LinearSensitivity(model, moment_model, kl_hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior_params:\n",
      "\talpha: [8.]\n",
      "\tprior_centroid_mean: [0.]\n",
      "\tprior_centroid_info: [0.1]\n",
      "\tprior_gamma_df: [8.]\n",
      "\tprior_gamma_inv_scale:\n",
      "[[0.62 0.   0.   0.  ]\n",
      " [0.   0.62 0.   0.  ]\n",
      " [0.   0.   0.62 0.  ]\n",
      " [0.   0.   0.   0.62]]\n"
     ]
    }
   ],
   "source": [
    "model_refit = deepcopy(model)\n",
    "print(model.prior_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def refit_with_alpha(new_alpha, model, linear_sens):\n",
    "    model_refit = deepcopy(model)\n",
    "    model_refit.prior_params['alpha'].set(new_alpha)\n",
    "    free_par_refit = linear_sens.predict_from_prior_params(\n",
    "        model_refit.prior_params.get_free())\n",
    "    model_refit.optimize_full(free_par_refit,\n",
    "        init_max_iter=100,\n",
    "        final_max_iter=500)\n",
    "    return free_par_refit, model_refit.global_vb_params.get_free()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14.]\n",
      "\n",
      "\n",
      "alpha:  1.0\n",
      "BGFS\n",
      "Iter: 0\t RMSE: 11.339413186360114\t Objective: -318.23613242970606\n",
      "Iter: 10\t RMSE: 11.337337615226355\t Objective: -318.267854925061\n",
      "Iter: 20\t RMSE: 11.337511705761491\t Objective: -318.2679244896362\n",
      "Iter: 30\t RMSE: 11.337511705790947\t Objective: -318.2679244896393\n",
      "Iter: 40\t RMSE: 11.336635583031917\t Objective: -318.2665290047097\n",
      "Iter: 50\t RMSE: 11.33744758173699\t Objective: -318.267910842387\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -318.267049\n",
      "         Iterations: 3\n",
      "         Function evaluations: 52\n",
      "         Gradient evaluations: 40\n",
      "Conditioned Newton:\n",
      "i =  0\n",
      "Iter: 60\t RMSE: 11.337181600951627\t Objective: -318.2737157621924\n",
      "Iter: 70\t RMSE: 11.337180550908906\t Objective: -318.27372215409844\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: -318.273722\n",
      "         Iterations: 25\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 16\n",
      "         Hessian evaluations: 0\n",
      "Iter 1: x_diff = 0.12273478440720355, f_diff = 0.006672848882317339\n",
      "i =  1\n",
      "Iter: 80\t RMSE: 11.293558473431002\t Objective: -318.18485350575884\n",
      "Iter: 90\t RMSE: 11.336381041279067\t Objective: -318.2785694460804\n",
      "Iter: 100\t RMSE: 11.33638108988115\t Objective: -318.2785691545616\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: -318.278569\n",
      "         Iterations: 24\n",
      "         Function evaluations: 26\n",
      "         Gradient evaluations: 2\n",
      "         Hessian evaluations: 0\n",
      "Iter 2: x_diff = 0.09202540321406348, f_diff = 0.004847000480253882\n",
      "i =  2\n",
      "Iter: 110\t RMSE: 11.336183016854463\t Objective: -318.2797613957191\n",
      "Iter: 120\t RMSE: 11.336381089692166\t Objective: -318.2785691557027\n",
      "Iter: 130\t RMSE: 11.336381089881195\t Objective: -318.27856915456135\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: -318.278569\n",
      "         Iterations: 24\n",
      "         Function evaluations: 26\n",
      "         Gradient evaluations: 1\n",
      "         Hessian evaluations: 0\n",
      "Iter 3: x_diff = 5.554541201990837e-14, f_diff = 1.1368683772161603e-13\n",
      "\n",
      "\n",
      "alpha:  2.0\n",
      "BGFS\n",
      "Iter: 0\t RMSE: 11.329284188612544\t Objective: -316.3208071307397\n",
      "Iter: 10\t RMSE: 11.324241168696503\t Objective: -316.33825089028784\n",
      "Iter: 20\t RMSE: 11.324727071338677\t Objective: -316.33865584047265\n",
      "Iter: 30\t RMSE: 11.324727086478056\t Objective: -316.3386558405356\n",
      "Iter: 40\t RMSE: 11.325064911934732\t Objective: -316.33846244199225\n",
      "Iter: 50\t RMSE: 11.324691684100639\t Objective: -316.3386535546183\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -316.338439\n",
      "         Iterations: 3\n",
      "         Function evaluations: 57\n",
      "         Gradient evaluations: 46\n",
      "Conditioned Newton:\n",
      "i =  0\n",
      "Iter: 60\t RMSE: 11.322234643860282\t Objective: -316.3536460751015\n",
      "Iter: 70\t RMSE: 11.324129432164433\t Objective: -316.3438320906748\n",
      "Iter: 80\t RMSE: 11.324129431267643\t Objective: -316.3438320956128\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: -316.343832\n",
      "         Iterations: 24\n",
      "         Function evaluations: 26\n",
      "         Gradient evaluations: 18\n",
      "         Hessian evaluations: 0\n",
      "Iter 1: x_diff = 0.12326207586084849, f_diff = 0.005393142616583191\n",
      "i =  1\n",
      "Iter: 90\t RMSE: 11.32394081148531\t Objective: -316.3448694875872\n",
      "Iter: 100\t RMSE: 11.323951898284465\t Objective: -316.34480880088717\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: -316.344809\n",
      "         Iterations: 24\n",
      "         Function evaluations: 26\n",
      "         Gradient evaluations: 6\n",
      "         Hessian evaluations: 0\n",
      "Iter 2: x_diff = 0.023100253583646382, f_diff = 0.0009767052375195817\n",
      "i =  2\n",
      "Iter: 110\t RMSE: 11.283855141611998\t Objective: -316.16608399503076\n",
      "Iter: 120\t RMSE: 11.323951855018164\t Objective: -316.344809037996\n",
      "Iter: 130\t RMSE: 11.323951898291519\t Objective: -316.3448088008499\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: -316.344809\n",
      "         Iterations: 23\n",
      "         Function evaluations: 25\n",
      "         Gradient evaluations: 1\n",
      "         Hessian evaluations: 0\n",
      "Iter 3: x_diff = 5.473919928444815e-14, f_diff = 3.410605131648481e-13\n",
      "\n",
      "\n",
      "alpha:  3.0\n",
      "BGFS\n",
      "Iter: 0\t RMSE: 11.319678065510754\t Objective: -314.43187283528226\n",
      "Iter: 10\t RMSE: 11.317461907121146\t Objective: -314.4378780548914\n",
      "Iter: 20\t RMSE: 11.317458913568982\t Objective: -314.4378780691909\n",
      "Iter: 30\t RMSE: 11.31745891463139\t Objective: -314.43787806919386\n",
      "Iter: 40\t RMSE: 11.31745891463139\t Objective: -314.43787806919397\n",
      "Iter: 50\t RMSE: 11.317423501516847\t Objective: -314.4378755574607\n",
      "Iter: 60\t RMSE: 11.317457905677268\t Objective: -314.4378780660576\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -314.437878\n",
      "         Iterations: 3\n",
      "         Function evaluations: 61\n",
      "         Gradient evaluations: 50\n",
      "Conditioned Newton:\n",
      "i =  0\n",
      "Iter: 70\t RMSE: 11.317465017334767\t Objective: -314.43788101660755\n",
      "Iter: 80\t RMSE: 11.31746569078119\t Objective: -314.43787798627676\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: -314.437878\n",
      "         Iterations: 26\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 4\n",
      "         Hessian evaluations: 0\n",
      "Iter 1: x_diff = 2.1574049404587958e-11, f_diff = 7.389644451905042e-13\n",
      "\n",
      "\n",
      "alpha:  4.0\n",
      "BGFS\n",
      "Iter: 0\t RMSE: 11.310030987735264\t Objective: -312.5597183118919\n",
      "Iter: 10\t RMSE: 11.308826345752504\t Objective: -312.5631595983796\n",
      "Iter: 20\t RMSE: 11.308953297016613\t Objective: -312.5631637528563\n",
      "Iter: 30\t RMSE: 11.308953297265742\t Objective: -312.56316375285724\n",
      "Iter: 40\t RMSE: 11.308953297265811\t Objective: -312.56316375285775\n",
      "Iter: 50\t RMSE: 11.308925418437491\t Objective: -312.5631634355308\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -312.563057\n",
      "         Iterations: 2\n",
      "         Function evaluations: 56\n",
      "         Gradient evaluations: 44\n",
      "Conditioned Newton:\n",
      "i =  0\n",
      "Iter: 60\t RMSE: 11.309033000983248\t Objective: -312.5650620093679\n",
      "Iter: 70\t RMSE: 11.309669161814803\t Objective: -312.56305719842\n",
      "Iter: 80\t RMSE: 11.309669162422264\t Objective: -312.56305719641085\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: -312.563057\n",
      "         Iterations: 25\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 3\n",
      "         Hessian evaluations: 0\n",
      "Iter 1: x_diff = 2.1256939351094184e-11, f_diff = 2.8421709430404007e-13\n",
      "\n",
      "\n",
      "alpha:  5.0\n",
      "BGFS\n",
      "Iter: 0\t RMSE: 11.299592829758984\t Objective: -310.70428621893143\n",
      "Iter: 10\t RMSE: 11.29905290096248\t Objective: -310.70508235475137\n",
      "Iter: 20\t RMSE: 11.299056664096744\t Objective: -310.7050828590053\n",
      "Iter: 30\t RMSE: 11.299056664096701\t Objective: -310.7050828590053\n",
      "Iter: 40\t RMSE: 11.299056664096703\t Objective: -310.70508285900553\n",
      "Iter: 50\t RMSE: 11.299056664096703\t Objective: -310.70508285900553\n",
      "Iter: 60\t RMSE: 11.299056664096703\t Objective: -310.70508285900553\n",
      "Iter: 70\t RMSE: 11.299056664096703\t Objective: -310.70508285900553\n",
      "Iter: 80\t RMSE: 11.299056664096703\t Objective: -310.70508285900553\n",
      "Iter: 90\t RMSE: 11.299056076243376\t Objective: -310.70508278059646\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -310.705083\n",
      "         Iterations: 2\n",
      "         Function evaluations: 96\n",
      "         Gradient evaluations: 84\n",
      "Conditioned Newton:\n",
      "i =  0\n",
      "Iter: 100\t RMSE: 11.298429959493427\t Objective: -310.7058931870025\n",
      "Iter: 110\t RMSE: 11.299056663498842\t Objective: -310.70508285987916\n",
      "Iter: 120\t RMSE: 11.299056664097263\t Objective: -310.7050828590044\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: -310.705083\n",
      "         Iterations: 23\n",
      "         Function evaluations: 25\n",
      "         Gradient evaluations: 1\n",
      "         Hessian evaluations: 0\n",
      "Iter 1: x_diff = 6.046183519126114e-14, f_diff = 7.958078640513122e-13\n",
      "\n",
      "\n",
      "alpha:  6.0\n",
      "BGFS\n",
      "Iter: 0\t RMSE: 11.287406249859808\t Objective: -308.8752124192508\n",
      "Iter: 10\t RMSE: 11.287164937430925\t Objective: -308.8752568398516\n",
      "Iter: 20\t RMSE: 11.287265480900428\t Objective: -308.8752646969459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 30\t RMSE: 11.287265481149351\t Objective: -308.8752646969467\n",
      "Iter: 40\t RMSE: 11.287265481148799\t Objective: -308.87526469694683\n",
      "Iter: 50\t RMSE: 11.287173570445955\t Objective: -308.87525812789727\n",
      "Iter: 60\t RMSE: 11.287261923773844\t Objective: -308.8752646858637\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -308.875257\n",
      "         Iterations: 1\n",
      "         Function evaluations: 62\n",
      "         Gradient evaluations: 51\n",
      "Conditioned Newton:\n",
      "i =  0\n",
      "Iter: 70\t RMSE: 11.287365473965666\t Objective: -308.87525774639084\n",
      "Iter: 80\t RMSE: 11.287367993499625\t Objective: -308.8752565906331\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: -308.875257\n",
      "         Iterations: 25\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 4\n",
      "         Hessian evaluations: 0\n",
      "Iter 1: x_diff = 2.0879585820726687e-11, f_diff = 1.1937117960769683e-12\n",
      "\n",
      "\n",
      "alpha:  7.0\n",
      "BGFS\n",
      "Iter: 0\t RMSE: 11.272653011617187\t Objective: -307.0883077411757\n",
      "Iter: 10\t RMSE: 11.27264808570628\t Objective: -307.0883077780419\n",
      "Iter: 20\t RMSE: 11.272648138038344\t Objective: -307.0883077788186\n",
      "Iter: 30\t RMSE: 11.222401838499797\t Objective: -294.6937700065319\n",
      "Iter: 40\t RMSE: 11.272649431963726\t Objective: -307.0883077900177\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -307.088308\n",
      "         Iterations: 0\n",
      "         Function evaluations: 42\n",
      "         Gradient evaluations: 31\n",
      "Conditioned Newton:\n",
      "i =  0\n",
      "Iter: 50\t RMSE: 11.27265037725927\t Objective: -307.0883078605446\n",
      "Iter: 60\t RMSE: 11.272653011614675\t Objective: -307.0883077411767\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: -307.088308\n",
      "         Iterations: 23\n",
      "         Function evaluations: 25\n",
      "         Gradient evaluations: 2\n",
      "         Hessian evaluations: 0\n",
      "Iter 1: x_diff = 4.249323549282424e-12, f_diff = 1.7053025658242404e-13\n",
      "\n",
      "\n",
      "alpha:  8.0\n",
      "BGFS\n",
      "Iter: 0\t RMSE: 11.255325883333482\t Objective: -305.35768659239903\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -305.357687\n",
      "         Iterations: 0\n",
      "         Function evaluations: 1\n",
      "         Gradient evaluations: 1\n",
      "Conditioned Newton:\n",
      "i =  0\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: -305.357687\n",
      "         Iterations: 0\n",
      "         Function evaluations: 2\n",
      "         Gradient evaluations: 1\n",
      "         Hessian evaluations: 0\n",
      "Iter 1: x_diff = 5.761927393543864e-14, f_diff = 6.252776074688882e-13\n",
      "\n",
      "\n",
      "alpha:  9.0\n",
      "BGFS\n",
      "Iter: 0\t RMSE: 11.236534873895792\t Objective: -303.6872274458831\n",
      "Iter: 10\t RMSE: 11.236925085613489\t Objective: -303.6872522369101\n",
      "Iter: 20\t RMSE: 11.236898364726905\t Objective: -303.6872686477857\n",
      "Iter: 30\t RMSE: 11.236898364727042\t Objective: -303.6872686477858\n",
      "Iter: 40\t RMSE: 11.236898364727042\t Objective: -303.687268647786\n",
      "Iter: 50\t RMSE: 11.236897216470512\t Objective: -303.6872687172444\n",
      "Iter: 60\t RMSE: 11.236897231239386\t Objective: -303.68726871668287\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -303.687257\n",
      "         Iterations: 1\n",
      "         Function evaluations: 63\n",
      "         Gradient evaluations: 51\n",
      "Conditioned Newton:\n",
      "i =  0\n",
      "Iter: 70\t RMSE: 11.23688117811191\t Objective: -303.68725699000515\n",
      "Iter: 80\t RMSE: 11.236871602455185\t Objective: -303.6872566421596\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: -303.687257\n",
      "         Iterations: 23\n",
      "         Function evaluations: 25\n",
      "         Gradient evaluations: 3\n",
      "         Hessian evaluations: 0\n",
      "Iter 1: x_diff = 3.2326905583836274e-11, f_diff = 0.0\n",
      "\n",
      "\n",
      "alpha:  10.0\n",
      "BGFS\n",
      "Iter: 0\t RMSE: 11.218003642389604\t Objective: -302.0674396394468\n",
      "Iter: 10\t RMSE: 11.218989378436925\t Objective: -302.06852730997707\n",
      "Iter: 20\t RMSE: 11.218959386180002\t Objective: -302.06853060641436\n",
      "Iter: 30\t RMSE: 11.21895938612024\t Objective: -302.0685306064176\n",
      "Iter: 40\t RMSE: 11.21895938612024\t Objective: -302.0685306064176\n",
      "Iter: 50\t RMSE: 11.218959652757963\t Objective: -302.06853060154054\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -302.068527\n",
      "         Iterations: 3\n",
      "         Function evaluations: 56\n",
      "         Gradient evaluations: 44\n",
      "Conditioned Newton:\n",
      "i =  0\n",
      "Iter: 60\t RMSE: 11.219395891466132\t Objective: -302.0687710595128\n",
      "Iter: 70\t RMSE: 11.218922416289166\t Objective: -302.068527034756\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: -302.068527\n",
      "         Iterations: 22\n",
      "         Function evaluations: 24\n",
      "         Gradient evaluations: 2\n",
      "         Hessian evaluations: 0\n",
      "Iter 1: x_diff = 6.949699930119957e-11, f_diff = 5.115907697472721e-13\n",
      "\n",
      "\n",
      "alpha:  11.0\n",
      "BGFS\n",
      "Iter: 0\t RMSE: 11.201369297494354\t Objective: -300.47909466788025\n",
      "Iter: 10\t RMSE: 11.203213585397965\t Objective: -300.48490184759356\n",
      "Iter: 20\t RMSE: 11.203181947052206\t Objective: -300.4849134806314\n",
      "Iter: 30\t RMSE: 11.203181967949988\t Objective: -300.48491348063277\n",
      "Iter: 40\t RMSE: 11.203162446846454\t Objective: -300.4849090300422\n",
      "Iter: 50\t RMSE: 11.203187933410858\t Objective: -300.48491306487074\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -300.484901\n",
      "         Iterations: 4\n",
      "         Function evaluations: 54\n",
      "         Gradient evaluations: 43\n",
      "Conditioned Newton:\n",
      "i =  0\n",
      "Iter: 60\t RMSE: 11.203170679391457\t Objective: -300.4849804832306\n",
      "Iter: 70\t RMSE: 11.203149698934329\t Objective: -300.4849013023487\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: -300.484901\n",
      "         Iterations: 24\n",
      "         Function evaluations: 26\n",
      "         Gradient evaluations: 2\n",
      "         Hessian evaluations: 0\n",
      "Iter 1: x_diff = 3.013128212648458e-13, f_diff = 2.8421709430404007e-13\n",
      "\n",
      "\n",
      "alpha:  12.0\n",
      "BGFS\n",
      "Iter: 0\t RMSE: 11.187863391413531\t Objective: -298.8991799751942\n",
      "Iter: 10\t RMSE: 11.191701034240758\t Objective: -298.91672623692494\n",
      "Iter: 20\t RMSE: 11.193012772638141\t Objective: -298.91805253471074\n",
      "Iter: 30\t RMSE: 11.193213512961544\t Objective: -298.9260089266174\n",
      "Iter: 40\t RMSE: 11.195821315558176\t Objective: -298.9409512375449\n",
      "Iter: 50\t RMSE: 11.19558960431351\t Objective: -298.94098477449296\n",
      "Iter: 60\t RMSE: 11.195587937026499\t Objective: -298.94098478082867\n",
      "Iter: 70\t RMSE: 11.195587937023149\t Objective: -298.9409847808289\n",
      "Iter: 80\t RMSE: 11.19569693798926\t Objective: -298.94097726506453\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -298.940981\n",
      "         Iterations: 18\n",
      "         Function evaluations: 89\n",
      "         Gradient evaluations: 78\n",
      "Conditioned Newton:\n",
      "i =  0\n",
      "Iter: 90\t RMSE: 11.214918522610727\t Objective: -298.6694839703986\n",
      "Iter: 100\t RMSE: 11.195502719814282\t Objective: -298.9409805415817\n",
      "Iter: 110\t RMSE: 11.195502701288744\t Objective: -298.9409805719182\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: -298.940981\n",
      "         Iterations: 27\n",
      "         Function evaluations: 29\n",
      "         Gradient evaluations: 4\n",
      "         Hessian evaluations: 0\n",
      "Iter 1: x_diff = 5.829722121708514e-12, f_diff = 1.7053025658242404e-13\n",
      "\n",
      "\n",
      "alpha:  13.0\n",
      "BGFS\n",
      "Iter: 0\t RMSE: 11.178252096796589\t Objective: -297.305196873401\n",
      "Iter: 10\t RMSE: 11.187313424593663\t Objective: -297.34703496345287\n",
      "Iter: 20\t RMSE: 11.18691084748619\t Objective: -297.3586662644781\n",
      "Iter: 30\t RMSE: 11.194389840693006\t Objective: -297.40276199778225\n",
      "Iter: 40\t RMSE: 11.193540334586926\t Objective: -297.4034256846046\n",
      "Iter: 50\t RMSE: 11.193540329085986\t Objective: -297.4034256884383\n",
      "Iter: 60\t RMSE: 11.19354032908599\t Objective: -297.403425688439\n",
      "Iter: 70\t RMSE: 11.19354032908599\t Objective: -297.403425688439\n",
      "Iter: 80\t RMSE: 11.19354032908599\t Objective: -297.403425688439\n",
      "Iter: 90\t RMSE: 11.19354032908599\t Objective: -297.403425688439\n",
      "Iter: 100\t RMSE: 11.19354032908599\t Objective: -297.403425688439\n",
      "Iter: 110\t RMSE: 11.19354032908599\t Objective: -297.4034256884388\n",
      "Iter: 120\t RMSE: 11.193540413317951\t Objective: -297.403425629719\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -297.403426\n",
      "         Iterations: 19\n",
      "         Function evaluations: 124\n",
      "         Gradient evaluations: 112\n",
      "Conditioned Newton:\n",
      "i =  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 130\t RMSE: 11.193552768983094\t Objective: -297.403355927812\n",
      "Iter: 140\t RMSE: 11.193540329097841\t Objective: -297.4034256883715\n",
      "Iter: 150\t RMSE: 11.193540329086055\t Objective: -297.4034256884383\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: -297.403426\n",
      "         Iterations: 32\n",
      "         Function evaluations: 34\n",
      "         Gradient evaluations: 8\n",
      "         Hessian evaluations: 0\n",
      "Iter 1: x_diff = 2.8752171650492375e-11, f_diff = 1.9326762412674725e-12\n",
      "\n",
      "\n",
      "alpha:  14.0\n",
      "BGFS\n",
      "Iter: 0\t RMSE: 11.172851707487283\t Objective: -295.6771177418732\n",
      "Iter: 10\t RMSE: 11.181324588307668\t Objective: -295.75775681535737\n",
      "Iter: 20\t RMSE: 11.17675055184041\t Objective: -295.80713400508375\n",
      "Iter: 30\t RMSE: 11.179847856591444\t Objective: -295.9043087615198\n",
      "Iter: 40\t RMSE: 11.17984785686515\t Objective: -295.9043087614395\n",
      "Iter: 50\t RMSE: 11.179847856591445\t Objective: -295.904308761519\n",
      "Iter: 60\t RMSE: 11.179881130015936\t Objective: -295.9042947194008\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -295.904004\n",
      "         Iterations: 19\n",
      "         Function evaluations: 67\n",
      "         Gradient evaluations: 55\n",
      "Conditioned Newton:\n",
      "i =  0\n",
      "Iter: 70\t RMSE: 11.180114565003977\t Objective: -295.9090384378259\n",
      "Iter: 80\t RMSE: 11.179536267856749\t Objective: -295.9040038821039\n",
      "Iter: 90\t RMSE: 11.179536267340106\t Objective: -295.9040038754372\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: -295.904004\n",
      "         Iterations: 25\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 3\n",
      "         Hessian evaluations: 0\n",
      "Iter 1: x_diff = 2.46321910893528e-11, f_diff = 2.9558577807620168e-12\n"
     ]
    }
   ],
   "source": [
    "alpha_vec = np.linspace(1, 14, num=14)\n",
    "print(alpha_vec)\n",
    "free_par_refit_list = []\n",
    "free_par_refit_lr_list = []\n",
    "for alpha in alpha_vec:\n",
    "    print('\\n\\nalpha: ', alpha)\n",
    "    free_par_refit, free_par_refit_lr = refit_with_alpha(alpha, model, linear_sens)\n",
    "    free_par_refit_list.append(free_par_refit)\n",
    "    free_par_refit_lr_list.append(free_par_refit_lr)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit_dict = gmm_utils.get_checkpoint_dictionary(model, kl_hessian, seed=453453)\n",
    "# base_alpha = model.prior_params['alpha'].get()\n",
    "# filename = 'ryan_iris_bnp_full_data_fit_alpha{}.json'.format(base_alpha)\n",
    "# json_output_file = os.path.join(\n",
    "#     git_repo,\n",
    "#     'BNP_sensitivity/GMM_clustering/iris_fits/',\n",
    "#     filename)\n",
    "# print('saving fit dict to ', json_output_file)\n",
    "# with open(json_output_file, 'w') as outfile:\n",
    "#     json.dump(fit_dict, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.843407204965061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2f936909e8>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2f93690f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 5\n",
    "print(np.linalg.norm(free_par_refit_list[i]))\n",
    "plt.plot(free_par_refit_list[i] - best_param, free_par_refit_lr_list[i] - best_param, 'k.')\n",
    "plt.plot(free_par_refit_list[i] - best_param, free_par_refit_list[i] - best_param, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../BNP_sensitivity/GMM_clustering/iris_fits/ryan_iris_bnp_full_data_fit_alpha8.0_alpha_refit.json\n",
      "saving fit dict to  ../../../BNP_sensitivity/GMM_clustering/iris_fits/ryan_iris_bnp_full_data_fit_alpha8.0_alpha_refit.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import json_tricks\n",
    "import checkpoints\n",
    "import re\n",
    "\n",
    "np_string = checkpoints.np_string\n",
    "fit_dict = {}\n",
    "fit_dict['free_par_refit_list' + np_string] = json_tricks.dumps(free_par_refit_list)\n",
    "fit_dict['free_par_refit_lr_list' + np_string] = json_tricks.dumps(free_par_refit_lr_list)\n",
    "fit_dict['alpha_vec' + np_string] = json_tricks.dumps(alpha_vec)\n",
    "fit_dict['json_input_file'] = json_input_file\n",
    "\n",
    "output_filename = re.sub('\\.json$', '', base_filename) + '_alpha_refit.json'\n",
    "json_output_file = os.path.join(\n",
    "    git_repo, 'BNP_sensitivity/GMM_clustering/iris_fits/',\n",
    "    output_filename)\n",
    "print(json_output_file)\n",
    "print('saving fit dict to ', json_output_file)\n",
    "with open(json_output_file, 'w') as outfile:\n",
    "    json.dump(fit_dict, outfile)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
