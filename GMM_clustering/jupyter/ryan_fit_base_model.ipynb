{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_repo = '../../..'\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#sys.path.insert(0, './../../../LinearResponseVariationalBayes.py')\n",
    "sys.path.insert(0, os.path.join(git_repo, 'BNP_sensitivity/GMM_clustering/'))\n",
    "#'./../')\n",
    "\n",
    "# Linear response libraries\n",
    "import LinearResponseVariationalBayes as vb\n",
    "import LinearResponseVariationalBayes.SparseObjectives as obj_lib\n",
    "#import LinearResponseVariationalBayes.ExponentialFamilies as ef\n",
    "\n",
    "# My libraries\n",
    "import gmm_clustering_lib as gmm_utils\n",
    "import modeling_lib \n",
    "import functional_sensitivity_lib as fun_sens_lib \n",
    "import utils_lib\n",
    "\n",
    "from scipy import spatial\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "# Just while you're experimenting\n",
    "from autograd import numpy as np\n",
    "from autograd import scipy as sp\n",
    "\n",
    "# import numpy as np\n",
    "# import scipy as sp\n",
    "\n",
    "np.random.seed(453453)\n",
    "\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_features, iris_species = utils_lib.load_data()\n",
    "dim = iris_features.shape[1]\n",
    "\n",
    "# Get some things that will be useful for plotting.\n",
    "pca_fit, pc_features, colors1, colors2 = utils_lib.get_plot_data(iris_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prior_params = gmm_utils.get_default_prior_params(dim)\n",
    "prior_params['alpha'].set(8.0)\n",
    "prior_params['prior_gamma_df'].set(8)\n",
    "prior_params['prior_gamma_inv_scale'].set(np.eye(dim) * 0.62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_approx = 12\n",
    "gh_deg = 8\n",
    "model = gmm_utils.DPGaussianMixture(\n",
    "    iris_features, k_approx, prior_params, gh_deg, use_logitnormal_sticks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run k-means init\n",
    "n_kmeans_init = 50\n",
    "init_global_free_param = model.cluster_and_set_inits(n_kmeans_init = n_kmeans_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BGFS\n",
      "Iter: 0\t RMSE: 5.4171664084976205\t Objective: 4927.074571257251\n",
      "Iter: 10\t RMSE: 10.722601299848941\t Objective: 3164.887763988899\n",
      "Iter: 20\t RMSE: 12.727784407538786\t Objective: 2095.64267039293\n",
      "Iter: 30\t RMSE: 12.825320826126164\t Objective: 403.25309073085555\n",
      "Iter: 40\t RMSE: 12.336111507461514\t Objective: -156.2818830513076\n",
      "Iter: 50\t RMSE: 12.153510031465627\t Objective: -265.9051915783531\n",
      "Iter: 60\t RMSE: 11.665404774476754\t Objective: -278.95947380457665\n",
      "Iter: 70\t RMSE: 11.243659114866814\t Objective: -287.3217971112322\n",
      "Iter: 80\t RMSE: 11.270215074059495\t Objective: -293.1724859597803\n",
      "Iter: 90\t RMSE: 11.279599774958886\t Objective: -297.93642331028184\n",
      "Iter: 100\t RMSE: 11.270952653637949\t Objective: -301.5500897148094\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: -302.542099\n",
      "         Iterations: 100\n",
      "         Function evaluations: 110\n",
      "         Gradient evaluations: 110\n",
      "Conditioned Newton:\n",
      "i =  0\n",
      "Iter: 110\t RMSE: 11.253624423017019\t Objective: -302.5420985282098\n",
      "Iter: 120\t RMSE: 11.246263059285315\t Objective: -305.2481721564943\n",
      "Iter: 130\t RMSE: 11.252832510017695\t Objective: -305.3431900441284\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: -305.357687\n",
      "         Iterations: 27\n",
      "         Function evaluations: 29\n",
      "         Gradient evaluations: 24\n",
      "         Hessian evaluations: 0\n",
      "Iter 1: x_diff = 31.82017370840149, f_diff = 2.8155880641871818\n",
      "i =  1\n",
      "Iter: 140\t RMSE: 11.255325883751928\t Objective: -305.3576865923987\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: -305.357687\n",
      "         Iterations: 0\n",
      "         Function evaluations: 2\n",
      "         Gradient evaluations: 1\n",
      "         Hessian evaluations: 0\n",
      "Iter 2: x_diff = 5.406742761837613e-14, f_diff = 9.663381206337363e-13\n",
      "Done. \n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "best_param, kl_hessian, kl_hessian_corrected, \\\n",
    "init_opt_time, newton_time, x_conv, f_conv, vb_opt = \\\n",
    "model.optimize_full(init_global_free_param,\n",
    "    init_max_iter=100,\n",
    "    final_max_iter=500)\n",
    "t_newton = time.time() - t0\n",
    "\n",
    "print('Done. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = deepcopy(model.global_vb_params.get_free())\n",
    "prior_free_params = deepcopy(model.prior_params.get_free())\n",
    "model.set_from_global_free_par(best_param)\n",
    "\n",
    "moment_model = gmm_utils.InterestingMoments(model)\n",
    "#linear_sens = gmm_utils.LinearSensitivity(model, moment_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kl_hessian = model.objective.fun_free_hessian(best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.60384671e+02, -5.25771180e-12, -2.12037829e-16,\n",
       "        -2.31582102e-12],\n",
       "       [-5.25771180e-12,  3.39103307e+00,  1.91647366e-03,\n",
       "         2.60831462e-02],\n",
       "       [-2.12037829e-16,  1.91647366e-03,  3.63505686e+00,\n",
       "         1.35393420e-02],\n",
       "       [-2.31582102e-12,  2.60831462e-02,  1.35393420e-02,\n",
       "         1.23617881e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_hessian[1:5, 1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190,)\n"
     ]
    }
   ],
   "source": [
    "dgdeta = np.zeros(kl_hessian.shape[0])\n",
    "dgdeta[0] = 1\n",
    "\n",
    "gh = np.linalg.solve(kl_hessian, g)\n",
    "print(gh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-11.603569234549244\n",
      "-11.603569234549244\n",
      "-6.599569940662139\n",
      "-1.0197093335387555\n"
     ]
    }
   ],
   "source": [
    "class VariationalDistributions(object):\n",
    "    def __init__(self, model, best_param, kl_hessian, dgdeta):\n",
    "        self.model = model\n",
    "        self.best_param = best_param\n",
    "        self.log_q_logit_stick_obj = obj_lib.Objective(\n",
    "            self.model.global_vb_params, self.get_log_q_logit_stick)\n",
    "        self.set_lr_matrix(kl_hessian, dgdeta)\n",
    "        \n",
    "    def set_lr_matrix(self, kl_hessian, dgdeta):\n",
    "        self.lr_mat = -1 * np.linalg.solve(kl_hessian, dgdeta)\n",
    "        \n",
    "    # In the logit_stick space\n",
    "    def get_log_q_logit_stick(self, logit_v, k):\n",
    "        mean = self.model.global_vb_params['v_sticks']['mean'].get()[k]\n",
    "        info = self.model.global_vb_params['v_sticks']['info'].get()[k]\n",
    "        return -0.5 * (info * (logit_v - mean) ** 2 - np.log(info))\n",
    "    \n",
    "    def get_log_p0_logit_stick(self, logit_v, k):\n",
    "        # See notes -- this is the base prior of stick k in the unconstrained space.\n",
    "        alpha = self.model.prior_params['alpha'].get()\n",
    "        return logit_v - (alpha + 1) * np.log1p(np.exp(logit_v))\n",
    "    \n",
    "    def get_influence(self, logit_v, k):\n",
    "        log_q = self.get_log_q_logit_stick(logit_v, k)\n",
    "        log_p0 = self.get_log_p0_logit_stick(logit_v, k)\n",
    "        \n",
    "        # TODO: use vector dot grad in autograd\n",
    "        log_q_grad = self.log_q_logit_stick_obj.fun_free_grad(\n",
    "            self.best_param, logit_v=logit_v, k=k)\n",
    "        return(self.lr_mat.T @ log_q_grad * np.exp(log_q - log_p0))\n",
    "    \n",
    "q_class = VariationalDistributions(model, best_param, kl_hessian, dgdeta)\n",
    "q_class.model.global_vb_params.set_free(best_param)\n",
    "print(q_class.get_log_q_logit_stick(0.5, 0))\n",
    "print(q_class.log_q_logit_stick_obj.fun_free(best_param, logit_v=0.5, k=0))\n",
    "\n",
    "#print(best_param)\n",
    "q_class.model.global_vb_params.set_free(best_param)\n",
    "#print(q_class.log_q_logit_stick_obj.fun_free_grad(best_param, logit_v=0.5, k=0))\n",
    "\n",
    "print(q_class.get_log_p0_logit_stick(0.1, 0))\n",
    "\n",
    "print(q_class.get_influence(logit_v=0, k=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class TestModel(object):\n",
    "    def __init__(self):\n",
    "        self.param = vb.ScalarParam('a')\n",
    "        self.obj = obj_lib.Objective(self.param, self.add)\n",
    "    def add(self, b):\n",
    "        return self.param.get() + b\n",
    "\n",
    "foo = TestModel()\n",
    "foo.param.set(5)\n",
    "foo.obj.fun_free(3,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
