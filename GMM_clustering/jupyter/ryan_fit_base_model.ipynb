{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_repo = '../../..'\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#sys.path.insert(0, './../../../LinearResponseVariationalBayes.py')\n",
    "sys.path.insert(0, os.path.join(git_repo, 'BNP_sensitivity/GMM_clustering/'))\n",
    "#'./../')\n",
    "\n",
    "# Linear response libraries\n",
    "import LinearResponseVariationalBayes as vb\n",
    "import LinearResponseVariationalBayes.SparseObjectives as obj_lib\n",
    "#import LinearResponseVariationalBayes.ExponentialFamilies as ef\n",
    "\n",
    "# My libraries\n",
    "import gmm_clustering_lib as gmm_utils\n",
    "import modeling_lib \n",
    "import functional_sensitivity_lib as fun_sens_lib \n",
    "import utils_lib\n",
    "\n",
    "from scipy import spatial\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "# Just while you're experimenting\n",
    "from autograd import numpy as np\n",
    "from autograd import scipy as sp\n",
    "\n",
    "# import numpy as np\n",
    "# import scipy as sp\n",
    "\n",
    "np.random.seed(453453)\n",
    "\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_features, iris_species = utils_lib.load_data()\n",
    "dim = iris_features.shape[1]\n",
    "\n",
    "# Get some things that will be useful for plotting.\n",
    "pca_fit, pc_features, colors1, colors2 = utils_lib.get_plot_data(iris_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prior_params = gmm_utils.get_default_prior_params(dim)\n",
    "prior_params['alpha'].set(8.0)\n",
    "prior_params['prior_gamma_df'].set(8)\n",
    "prior_params['prior_gamma_inv_scale'].set(np.eye(dim) * 0.62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_approx = 12\n",
    "gh_deg = 8\n",
    "model = gmm_utils.DPGaussianMixture(\n",
    "    iris_features, k_approx, prior_params, gh_deg, use_logitnormal_sticks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run k-means init\n",
    "n_kmeans_init = 50\n",
    "init_global_free_param = model.cluster_and_set_inits(n_kmeans_init = n_kmeans_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BGFS\n",
      "Iter: 0\t RMSE: 5.4171664084976205\t Objective: 4927.074571257251\n",
      "Iter: 10\t RMSE: 10.722601299848941\t Objective: 3164.887763988899\n",
      "Iter: 20\t RMSE: 12.727784407538786\t Objective: 2095.64267039293\n",
      "Iter: 30\t RMSE: 12.825320826126164\t Objective: 403.25309073085555\n",
      "Iter: 40\t RMSE: 12.336111507461514\t Objective: -156.2818830513076\n",
      "Iter: 50\t RMSE: 12.153510031465627\t Objective: -265.9051915783531\n",
      "Iter: 60\t RMSE: 11.665404774476754\t Objective: -278.95947380457665\n",
      "Iter: 70\t RMSE: 11.243659114866814\t Objective: -287.3217971112322\n",
      "Iter: 80\t RMSE: 11.270215074059495\t Objective: -293.1724859597803\n",
      "Iter: 90\t RMSE: 11.279599774958886\t Objective: -297.93642331028184\n",
      "Iter: 100\t RMSE: 11.270952653637949\t Objective: -301.5500897148094\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: -302.542099\n",
      "         Iterations: 100\n",
      "         Function evaluations: 110\n",
      "         Gradient evaluations: 110\n",
      "Conditioned Newton:\n",
      "i =  0\n",
      "Iter: 110\t RMSE: 11.253624423017019\t Objective: -302.5420985282098\n",
      "Iter: 120\t RMSE: 11.246263059285315\t Objective: -305.2481721564943\n",
      "Iter: 130\t RMSE: 11.252832510017695\t Objective: -305.3431900441284\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: -305.357687\n",
      "         Iterations: 27\n",
      "         Function evaluations: 29\n",
      "         Gradient evaluations: 24\n",
      "         Hessian evaluations: 0\n",
      "Iter 1: x_diff = 31.82017370840149, f_diff = 2.8155880641871818\n",
      "i =  1\n",
      "Iter: 140\t RMSE: 11.255325883751928\t Objective: -305.3576865923987\n",
      "Warning: A bad approximation caused failure to predict improvement.\n",
      "         Current function value: -305.357687\n",
      "         Iterations: 0\n",
      "         Function evaluations: 2\n",
      "         Gradient evaluations: 1\n",
      "         Hessian evaluations: 0\n",
      "Iter 2: x_diff = 5.406742761837613e-14, f_diff = 9.663381206337363e-13\n",
      "Done. \n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "best_param, kl_hessian, kl_hessian_corrected, \\\n",
    "init_opt_time, newton_time, x_conv, f_conv, vb_opt = \\\n",
    "model.optimize_full(init_global_free_param,\n",
    "    init_max_iter=100,\n",
    "    final_max_iter=500)\n",
    "t_newton = time.time() - t0\n",
    "\n",
    "print('Done. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving fit dict to  ../../../BNP_sensitivity/GMM_clustering/iris_fits/ryan_iris_bnp_full_data_fit.json\n"
     ]
    }
   ],
   "source": [
    "fit_dict = model.get_checkpoint_dictionary(seed=453453)\n",
    "json_output_file = os.path.join(\n",
    "    git_repo, 'BNP_sensitivity/GMM_clustering/iris_fits/ryan_iris_bnp_full_data_fit.json')\n",
    "print('saving fit dict to ', json_output_file)\n",
    "with open(json_output_file, 'w') as outfile:\n",
    "    json.dump(fit_dict, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = deepcopy(model.global_vb_params.get_free())\n",
    "prior_free_params = deepcopy(model.prior_params.get_free())\n",
    "model.set_from_global_free_par(best_param)\n",
    "\n",
    "moment_model = gmm_utils.InterestingMoments(model)\n",
    "#linear_sens = gmm_utils.LinearSensitivity(model, moment_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kl_hessian = model.objective.fun_free_hessian(best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190,)\n"
     ]
    }
   ],
   "source": [
    "dgdeta = np.zeros(kl_hessian.shape[0])\n",
    "dgdeta[0] = 1\n",
    "\n",
    "gh = np.linalg.solve(kl_hessian, dgdeta)\n",
    "print(gh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.k_approx\n",
    "model.global_vb_params['v_sticks']['mean'].get().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'obj_lib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-eb63bd70e097>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mq_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_sens_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStickSensitivity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_hessian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdgdeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mq_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_vb_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_free\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_log_q_logit_stick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_q_logit_stick_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun_free\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogit_v\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git_repos/BNP_sensitivity/GMM_clustering/functional_sensitivity_lib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, best_param, kl_hessian, dgdeta)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_param\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         self.log_q_logit_stick_obj = obj_lib.Objective(\n\u001b[0m\u001b[1;32m     22\u001b[0m             self.model.global_vb_params, self.get_log_q_logit_stick)\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_lr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkl_hessian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdgdeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'obj_lib' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "q_class = fun_sens_lib.StickSensitivity(model, best_param, kl_hessian, dgdeta)\n",
    "q_class.model.global_vb_params.set_free(best_param)\n",
    "print(q_class.get_log_q_logit_stick(0.5, 0))\n",
    "print(q_class.log_q_logit_stick_obj.fun_free(best_param, logit_v=0.5, k=0))\n",
    "\n",
    "#print(best_param)\n",
    "q_class.model.global_vb_params.set_free(best_param)\n",
    "#print(q_class.log_q_logit_stick_obj.fun_free_grad(best_param, logit_v=0.5, k=0))\n",
    "\n",
    "print('---------\\n')\n",
    "print(q_class.get_log_q_logit_stick(0.5, 0))\n",
    "print(q_class.get_log_p0_logit_stick(0.1))\n",
    "\n",
    "print('\\n--------- all:')\n",
    "print(q_class.get_log_q_logit_all_sticks(0.1))\n",
    "\n",
    "print('---------\\n')\n",
    "print(q_class.get_single_stick_influence(logit_v=0, k=0))\n",
    "print(q_class.get_all_stick_influence(logit_v=0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_grid = np.linspace(1e-3, 1 - 1e-3, num=100)\n",
    "logit_v_grid = np.log(v_grid / (1 - v_grid))\n",
    "\n",
    "plt.figure()\n",
    "influence_grid = np.array(\n",
    "    [ q_class.get_all_stick_influence(logit_v=logit_v) for\n",
    "      logit_v in logit_v_grid ])\n",
    "plt.plot(v_grid, influence_grid, 'k')\n",
    "plt.figure()\n",
    "plt.plot(logit_v_grid, influence_grid, 'k')\n",
    "\n",
    "logit_v_min = np.log(1e-3 / (1 - 1e-3))\n",
    "logit_v_max = np.log((1 - 1e-3) / 1e-3)\n",
    "logit_v_grid = np.linspace(logit_v_min, logit_v_max, num=100)\n",
    "v_grid = np.exp(logit_v_grid) / (1 + np.exp(logit_v_grid))\n",
    "\n",
    "influence_grid = np.array(\n",
    "    [ q_class.get_all_stick_influence(logit_v=logit_v) for\n",
    "      logit_v in logit_v_grid ])\n",
    "plt.figure()\n",
    "plt.plot(v_grid, influence_grid, 'k')\n",
    "plt.figure()\n",
    "plt.plot(logit_v_grid, influence_grid, 'k')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "v_grid = np.linspace(1e-3, 1 - 1e-3, num=100)\n",
    "logit_v_grid = np.log(v_grid / (1 - v_grid))\n",
    "\n",
    "for k in range(model.k_approx - 1):\n",
    "    influence_grid = np.array(\n",
    "        [ q_class.get_single_stick_influence(logit_v=logit_v, k=k) for\n",
    "          logit_v in logit_v_grid ])\n",
    "    plt.figure()\n",
    "    plt.plot(logit_v_grid, influence_grid, 'k')\n",
    "    plt.title(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
