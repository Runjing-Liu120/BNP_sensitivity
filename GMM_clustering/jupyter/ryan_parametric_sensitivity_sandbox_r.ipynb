{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(reticulate)\n",
    "library(ggplot2)\n",
    "library(reshape2)\n",
    "library(dplyr)\n",
    "use_python(\"/usr/bin/python3\")\n",
    "\n",
    "git_repo_loc=Sys.getenv(\"GIT_REPO_LOC\")\n",
    "`%_%` <- function(x, y) { paste(x, y, sep=\"\")}\n",
    "\n",
    "py_run_string(\"import sys\")\n",
    "py_run_string(\"import pickle\")\n",
    "for (py_lib in c(\"LinearResponseVariationalBayes.py\",\n",
    "                 \"BNP_sensitivity/GMM_clustering/\",\n",
    "                 \"autograd\")) {\n",
    "    py_run_string(\"sys.path.append('\" %_% file.path(git_repo_loc, py_lib) %_% \"')\")\n",
    "}\n",
    "py_run_string(\"\n",
    "import os\n",
    "\n",
    "import LinearResponseVariationalBayes as vb\n",
    "import LinearResponseVariationalBayes.SparseObjectives as obj_lib\n",
    "\n",
    "# Local libraries\n",
    "import gmm_clustering_lib as gmm_utils\n",
    "import modeling_lib \n",
    "import functional_sensitivity_lib as fun_sens_lib \n",
    "import utils_lib\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import json \n",
    "\n",
    "git_repo = os.environ['GIT_REPO_LOC']\n",
    "\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "py_run_string(\"\n",
    "# Load results from previous fit.\n",
    "#filename = 'ryan_iris_bnp_full_data_fit_alpha2.0.json'\n",
    "#filename = 'ryan_iris_bnp_full_data_fit_alpha8.0.json'\n",
    "filename = 'ryan_simulation_bnp_full_data_fit_alpha8.0.json'\n",
    "json_input_file = os.path.join(\n",
    "    git_repo,\n",
    "   'BNP_sensitivity/GMM_clustering/iris_fits/',\n",
    "   filename)\n",
    "\n",
    "with open(json_input_file, 'r') as fp:\n",
    "    fit_dict = json.load(fp)\n",
    "    model = gmm_utils.get_model_from_checkpoint(fit_dict)\n",
    "    model_ = gmm_utils.get_model_from_checkpoint(fit_dict)\n",
    "    best_param = model.global_vb_params.get_free()\n",
    "    kl_hessian = gmm_utils.get_kl_hessian_from_checkpoint(fit_dict)\n",
    "\n",
    "moment_model = gmm_utils.InterestingMoments(model)\n",
    "dg_deta = moment_model.get_moment_jacobian(best_param)\n",
    "linear_sens = gmm_utils.LinearSensitivity(model, moment_model, kl_hessian)\n",
    "\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "py_run_string(\"\n",
    "model_refit = deepcopy(model)\n",
    "print(model.prior_params)\n",
    "\n",
    "def refit_with_alpha(new_alpha, model, linear_sens):\n",
    "    model_refit = deepcopy(model)\n",
    "    model_refit.prior_params['alpha'].set(new_alpha)\n",
    "    free_par_refit = linear_sens.predict_from_prior_params(\n",
    "        model_refit.prior_params.get_free())\n",
    "    model_refit.optimize_full(free_par_refit,\n",
    "        init_max_iter=100,\n",
    "        final_max_iter=500)\n",
    "    return free_par_refit, model_refit.global_vb_params.get_free()\n",
    "\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "py_run_string(\"\n",
    "alpha_vec = np.linspace(1, 14, num=14)\n",
    "\n",
    "print(alpha_vec)\n",
    "free_par_refit_list = []\n",
    "free_par_refit_lr_list = []\n",
    "for alpha in alpha_vec:\n",
    "    print(alpha)\n",
    "    free_par_refit_lr, free_par_refit = refit_with_alpha(alpha, model, linear_sens)\n",
    "    free_par_refit_list.append(free_par_refit)\n",
    "    free_par_refit_lr_list.append(free_par_refit_lr)\n",
    "\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_main <- reticulate::import_main()\n",
    "\n",
    "GetResultDataFrame <- function(free_par, this_alpha, this_method) {\n",
    "    py_main$moment_model$set_moments_from_free_par(free_par)\n",
    "    centroids <- py_main$moment_model$moment_params['centroids']$get()\n",
    "    cluster_weights <- py_main$moment_model$moment_params['cluster_weights']$get()\n",
    "\n",
    "    centroid_df <- melt(centroids) %>%\n",
    "        rename(dim=Var1, k=Var2) %>%\n",
    "        mutate(alpha=this_alpha, method=this_method, variable=\"centroid\")\n",
    "\n",
    "    weight_df <- data.frame(value=cluster_weights) %>%\n",
    "        mutate(dim=-1, k=1:length(cluster_weights)) %>%\n",
    "        mutate(alpha=this_alpha, method=this_method, variable=\"cluster_weight\")\n",
    "\n",
    "    return(rbind(weight_df, centroid_df))\n",
    "}\n",
    "\n",
    "\n",
    "df_list <- list()\n",
    "\n",
    "for (i in 1:length(py_main$alpha_vec)) {\n",
    "    df_list[[length(df_list) + 1]]  <-\n",
    "        rbind(\n",
    "            GetResultDataFrame(\n",
    "                py_main$free_par_refit_list[[i]],\n",
    "                py_main$alpha_vec[i],\n",
    "                'truth'),\n",
    "            GetResultDataFrame(\n",
    "                py_main$free_par_refit_lr_list[[i]],\n",
    "                py_main$alpha_vec[i],\n",
    "                'lr')\n",
    "        )\n",
    "}\n",
    "df <- do.call(rbind, df_list)\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_k <- filter(df, variable == \"cluster_weight\", method == \"truth\") %>%\n",
    "    ungroup() %>% group_by(k) %>%\n",
    "    summarize(max_weight=max(value)) %>%\n",
    "    filter(max_weight > 0.01) %>%\n",
    "    `[[`('k')\n",
    "big_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cast <- dcast(df, alpha + dim + k + variable ~ method, value.var=\"value\")\n",
    "head(df_cast)\n",
    "ggplot(df_cast) +\n",
    "    geom_histogram(aes(x=lr - truth), bins=50)\n",
    "# ggplot(df_cast) +\n",
    "#     geom_line(aes(x=alpha, y=value, color=paste(dim, k))) +\n",
    "#     facet_grid(dim ~ method, scales=\"free\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_alpha <- py_main$model$prior_params['alpha']$get()\n",
    "ggplot(filter(df, k %in% big_k)) +\n",
    "    geom_line(aes(x=alpha, y=value, color=method)) +\n",
    "    geom_vline(aes(xintercept=base_alpha), color=\"gray\") +\n",
    "    facet_grid(dim ~ k, scales=\"free\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
