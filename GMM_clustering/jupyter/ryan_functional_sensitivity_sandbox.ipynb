{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "git_repo = '../../..'\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.join(git_repo, 'BNP_sensitivity/GMM_clustering/'))\n",
    "\n",
    "# Linear response libraries\n",
    "import LinearResponseVariationalBayes as vb\n",
    "import LinearResponseVariationalBayes.SparseObjectives as obj_lib\n",
    "import LinearResponseVariationalBayes.OptimizationUtils as opt_lib\n",
    "\n",
    "# Local libraries\n",
    "import gmm_clustering_lib as gmm_utils\n",
    "import modeling_lib \n",
    "import functional_sensitivity_lib as fun_sens_lib \n",
    "import utils_lib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from autograd import numpy as np\n",
    "from autograd import scipy as sp\n",
    "\n",
    "# import numpy as np\n",
    "# import scipy as sp\n",
    "\n",
    "np.random.seed(453453)\n",
    "\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load results from previous fit.\n",
    "filename = 'ryan_iris_bnp_full_data_fit_alpha8.0.json'\n",
    "#filename = 'ryan_simulation_bnp_full_data_fit_alpha1.0.json'\n",
    "#filename = 'ryan_simulation_bnp_full_data_fit_alpha1.0.json'\n",
    "json_input_file = os.path.join(\n",
    "    git_repo,\n",
    "    'BNP_sensitivity/GMM_clustering/iris_fits/',\n",
    "    filename)\n",
    "\n",
    "with open(json_input_file, 'r') as fp:\n",
    "    fit_dict = json.load(fp)\n",
    "    model = gmm_utils.get_model_from_checkpoint(fit_dict)\n",
    "    model_ = gmm_utils.get_model_from_checkpoint(fit_dict)\n",
    "    best_param = model.global_vb_params.get_free()\n",
    "    kl_hessian = gmm_utils.get_kl_hessian_from_checkpoint(fit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moment_model = gmm_utils.InterestingMoments(model)\n",
    "dg_deta = moment_model.get_moment_jacobian(best_param)\n",
    "#linear_sens = gmm_utils.LinearSensitivity(model, moment_model, kl_hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moment_model.set_moments_from_free_par(best_param)\n",
    "print(moment_model.moment_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.prior_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a perturbation in the logit v space.\n",
    "\n",
    "phi_center = -2\n",
    "#phi_log_rescale = stick_sens.get_log_p0_logit_stick(phi_center)\n",
    "phi_log_rescale = -np.log(0.5)\n",
    "print(phi_log_rescale)\n",
    "def log_phi(logit_v):\n",
    "    return(-0.5 * (logit_v - phi_center) ** 2 - phi_log_rescale)\n",
    "\n",
    "def phi(logit_v):\n",
    "    return np.exp(log_phi(logit_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This perturbation class is based on the contamination model\n",
    "\n",
    "$$\n",
    "p_c(\\theta | \\epsilon, \\phi) =  p_0(\\theta) \\left(1 + \\epsilon \\phi(\\theta) \\right)\n",
    "$$\n",
    "\n",
    "This corresponds to Gustafson's linear model.  One big problem is that you must take $\\epsilon \\rightarrow \\infty$.  Another is that, even if you set it up as a normalized mixture, the scale of the perturbation determines the derivative.  I think it is worth experimenting with the model\n",
    "\n",
    "\\begin{align}\n",
    "p_c(\\theta | \\epsilon, \\phi) &= p_0(\\theta)^{1 - \\epsilon} p_1(\\theta)^\\epsilon \\\\\n",
    "& = p_0(\\theta) \\left(\\frac{p_1(\\theta)}{p_0(\\theta)}\\right)^\\epsilon \\\\\n",
    "& =: p_0(\\theta) (C_1 \\phi(\\theta)) ^ \\epsilon\n",
    "\\end{align}\n",
    "\n",
    "because, among other things, it is invariant to the scaling $C_1$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as osp\n",
    "\n",
    "class PriorPerturbation(object):\n",
    "    def __init__(self, model, log_phi, epsilon=1.0):\n",
    "        self.logit_v_lb = -4\n",
    "        self.logit_v_ub = 4\n",
    "        \n",
    "        self.gustafson_style = False\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "        self.epsilon_param = vb.ScalarParam('epsilon', lb=0.0)\n",
    "        self.epsilon_param.set(epsilon)\n",
    "\n",
    "        self.set_log_phi(log_phi)\n",
    "        \n",
    "        if not model.vb_params.use_logitnormal_sticks:\n",
    "            raise NotImplementedError(\n",
    "                'functional sensitivty only computed with logitnormal sticks')\n",
    "        self.model = model\n",
    "        \n",
    "        self.objective = obj_lib.Objective(\n",
    "            self.model.global_vb_params, self.get_perturbed_kl)\n",
    "    \n",
    "    #################\n",
    "    # Functions that are used for optimization and sensitivity.\n",
    "        \n",
    "    def get_e_log_perturbation(self):\n",
    "        if self.gustafson_style:\n",
    "            perturbation_fun = \\\n",
    "                lambda logit_v: \\\n",
    "                    (1 + self.epsilon_param.get() * np.exp(self.log_phi(logit_v)))\n",
    "        else:\n",
    "            perturbation_fun = \\\n",
    "                lambda logit_v: self.log_phi(logit_v) * self.epsilon_param.get()\n",
    "\n",
    "        e_perturbation_vec = gmm_utils.get_e_func_logit_stick_vec(\n",
    "            self.model.vb_params, perturbation_fun)\n",
    "        return -1 * np.sum(e_perturbation_vec)\n",
    "                \n",
    "    def get_perturbed_kl(self):\n",
    "        return self.get_e_log_perturbation() + self.model.set_z_get_kl()\n",
    "\n",
    "    #################\n",
    "    # Functions that are used for graphing and the influence function.\n",
    "\n",
    "    # The log variational density of stick k at logit_v\n",
    "    # in the logit_stick space.\n",
    "    def get_log_q_logit_stick(self, logit_v, k):\n",
    "        mean = self.model.global_vb_params['v_sticks']['mean'].get()[k]\n",
    "        info = self.model.global_vb_params['v_sticks']['info'].get()[k]\n",
    "        return -0.5 * (info * (logit_v - mean) ** 2 - np.log(info))\n",
    "\n",
    "    # Return a vector of log variational densities for all sticks at logit_v\n",
    "    # in the logit stick space.\n",
    "    def get_log_q_logit_all_sticks(self, logit_v):\n",
    "        mean = self.model.global_vb_params['v_sticks']['mean'].get()\n",
    "        info = self.model.global_vb_params['v_sticks']['info'].get()\n",
    "        return -0.5 * (info * (logit_v - mean) ** 2 - np.log(info))\n",
    "\n",
    "    def get_log_p0(self, v):\n",
    "        alpha = self.model.prior_params['alpha'].get()\n",
    "        return (alpha - 1) * np.log1p(v) - self.log_norm_p0\n",
    "\n",
    "    def get_log_p0_logit(self, logit_v):\n",
    "        alpha = self.model.prior_params['alpha'].get()\n",
    "        return \\\n",
    "            logit_v - (alpha + 1) * np.log1p(np.exp(logit_v)) - \\\n",
    "            self.log_norm_p0_logit\n",
    "\n",
    "    def get_log_pc(self, v):\n",
    "        logit_v = np.log(v) - np.log(1 - v)\n",
    "        epsilon = self.epsilon_param.get()\n",
    "        if np.abs(epsilon) < 1e-8:\n",
    "            return self.get_log_p0(v)            \n",
    "\n",
    "        if self.gustafson_style:\n",
    "            log_epsilon = np.log(epsilon)\n",
    "            return \\\n",
    "                self.get_log_p0(v) + \\\n",
    "                self.log_phi(logit_v) + \\\n",
    "                log_epsilon - \\\n",
    "                self.log_norm_pc\n",
    "        else:\n",
    "            assert epsilon <= 1\n",
    "            return \\\n",
    "                self.get_log_p0(v) + \\\n",
    "                epsilon * self.log_phi(logit_v) - \\\n",
    "                self.log_norm_pc\n",
    "\n",
    "    def get_log_pc_logit(self, logit_v):\n",
    "        epsilon = self.epsilon_param.get()\n",
    "        if np.abs(epsilon) < 1e-8:\n",
    "            return self.get_log_p0_logit(logit_v)            \n",
    "\n",
    "        if self.gustafson_style:\n",
    "            log_epsilon = np.log(epsilon)\n",
    "            return \\\n",
    "                self.get_log_p0_logit(logit_v) + \\\n",
    "                self.log_phi(logit_v) + \\\n",
    "                log_epsilon - \\\n",
    "                self.log_norm_pc_logit\n",
    "        else:\n",
    "            assert epsilon <= 1\n",
    "            return \\\n",
    "                self.get_log_p0_logit(logit_v) + \\\n",
    "                epsilon * self.log_phi(logit_v) - \\\n",
    "                self.log_norm_pc_logit\n",
    "\n",
    "    ###################################\n",
    "    # Setting functions for initialization\n",
    "\n",
    "    def set_epsilon(self, epsilon):\n",
    "        self.epsilon_param.set(epsilon)\n",
    "        self.set_log_phi(self.log_phi)\n",
    "        \n",
    "    def set_log_phi(self, log_phi):\n",
    "        # Set attributes derived from phi and epsilon\n",
    "        \n",
    "        # Initial values for the log normalzing constants which will be set below.\n",
    "        self.log_norm_p0 = 0\n",
    "        self.log_norm_pc = 0\n",
    "        self.log_norm_p0_logit = 0\n",
    "        self.log_norm_pc_logit = 0\n",
    "\n",
    "        self.log_phi = log_phi\n",
    "        \n",
    "        norm_p0, _ = osp.integrate.quadrature(\n",
    "            lambda v: np.exp(self.get_log_p0(v)), 0, 1)\n",
    "        assert norm_p0 > 0 \n",
    "        self.log_norm_p0 = np.log(norm_p0)\n",
    "\n",
    "        norm_pc, _ = osp.integrate.quadrature(\n",
    "            lambda v: np.exp(self.get_log_pc(v)),\n",
    "            0, 1)\n",
    "        assert norm_pc > 0 \n",
    "        self.log_norm_pc = np.log(norm_pc)\n",
    "        \n",
    "        norm_p0_logit, _ = osp.integrate.quadrature(\n",
    "            lambda logit_v: np.exp(self.get_log_p0_logit(logit_v)),\n",
    "            self.logit_v_lb, self.logit_v_ub)\n",
    "        assert norm_p0_logit > 0 \n",
    "        self.log_norm_p0_logit = np.log(norm_p0_logit)\n",
    "\n",
    "        norm_pc_logit, _ = osp.integrate.quadrature(\n",
    "            lambda logit_v: np.exp(self.get_log_pc_logit(logit_v)),\n",
    "            self.logit_v_lb, self.logit_v_ub)\n",
    "        assert norm_pc_logit > 0 \n",
    "        self.log_norm_pc_logit = np.log(norm_pc_logit)\n",
    "        \n",
    "\n",
    "prior_perturbation = PriorPerturbation(model, log_phi)\n",
    "print(\n",
    "    prior_perturbation.log_norm_p0,\n",
    "    prior_perturbation.log_norm_pc,\n",
    "    prior_perturbation.log_norm_p0_logit,\n",
    "    prior_perturbation.log_norm_pc_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_perturbation.set_epsilon(1.0)\n",
    "\n",
    "logit_v_grid = np.linspace(-4, 4, 200)\n",
    "v_grid = np.exp(logit_v_grid) / (1 + np.exp(logit_v_grid))\n",
    "\n",
    "print('phi max: ', np.max(phi(logit_v_grid)))\n",
    "\n",
    "plt.figure(1, figsize=(18, 5))\n",
    "\n",
    "#plt.plot(v_grid, phi(logit_v_grid))\n",
    "plt.subplot(141)\n",
    "plt.plot(logit_v_grid, prior_perturbation.get_log_p0_logit(logit_v_grid))\n",
    "plt.plot(logit_v_grid, prior_perturbation.get_log_pc_logit(logit_v_grid))\n",
    "plt.title('Log priors in logit space')\n",
    "\n",
    "plt.subplot(142)\n",
    "plt.plot(logit_v_grid, np.exp(prior_perturbation.log_phi(logit_v_grid)))\n",
    "plt.title('phi in logit space')\n",
    "\n",
    "plt.subplot(143)\n",
    "plt.plot(v_grid, np.exp(prior_perturbation.get_log_p0(v_grid)))\n",
    "plt.plot(v_grid, np.exp(prior_perturbation.get_log_pc(v_grid)))\n",
    "plt.title('Priors in stick space')\n",
    "\n",
    "plt.subplot(144)\n",
    "plt.plot(logit_v_grid, np.exp(prior_perturbation.get_log_p0_logit(logit_v_grid)))\n",
    "plt.plot(logit_v_grid, np.exp(prior_perturbation.get_log_pc_logit(logit_v_grid)))\n",
    "plt.title('Priors in logit space')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Choose the number of GH points.\n",
    "import LinearResponseVariationalBayes.ExponentialFamilies as ef\n",
    "model.global_vb_params.set_free(best_param)\n",
    "vb_params = deepcopy(model.vb_params)\n",
    "\n",
    "perturbed_log_density = lambda x : np.log(1.0 + phi(x))\n",
    "\n",
    "expected_perturbations_list = []\n",
    "gh_deg_list = np.arange(3, 100, 1)\n",
    "for gh_deg in gh_deg_list:\n",
    "    gmm_utils.set_gauss_hermite_points(vb_params, gh_deg=gh_deg)\n",
    "    expected_perturbations_list.append(\n",
    "        gmm_utils.get_e_log_perturbation_vec(vb_params, phi))\n",
    "\n",
    "expected_perturbations_list = np.array(expected_perturbations_list)\n",
    "#print(expected_perturbations_list.shape)\n",
    "diffs = (expected_perturbations_list[1:, :] - \\\n",
    "         expected_perturbations_list[:-1, :]) / \\\n",
    "        np.abs(expected_perturbations_list[1:, :] + 1e-6)\n",
    "#print(np.max(diffs, axis=1))\n",
    "max_diffs = np.max(np.abs(diffs), axis=1) \n",
    "gh_deg_threshold = np.argmax(max_diffs < 1e-5)\n",
    "gh_deg = max(20, gh_deg_threshold)\n",
    "print(gh_deg, gh_deg_threshold, len(max_diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# First fit with no perturbation but the increased number of gh points.\n",
    "\n",
    "model.objective.logger.print_every = 10\n",
    "gmm_utils.set_gauss_hermite_points(model.vb_params, gh_deg=gh_deg)\n",
    "\n",
    "best_param_0, converged, x_conv, f_conv, grad_conv, obj_opt, opt_results = \\\n",
    "    opt_lib.repeatedly_optimize(\n",
    "        objective=prior_perturbation.objective,\n",
    "        optimization_fun=lambda x: gmm_utils.precondition_and_optimize(model.objective, x),\n",
    "        init_x=best_param,\n",
    "        initial_optimization_fun=None,\n",
    "        max_iter=100,\n",
    "        gtol=1e-8, ftol=1e-8, xtol=1e-8, disp=False,\n",
    "        keep_intermediate_optimizations=True)\n",
    "\n",
    "kl_hessian_0 = model.objective.fun_free_hessian(best_param_0)\n",
    "    \n",
    "print('Done. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This expects the hyperparameter to be at its optimal value.\n",
    "prior_perturbation.set_epsilon(0.0)\n",
    "epsilon_sensitivity = \\\n",
    "    obj_lib.ParametricSensitivity(\n",
    "        objective_fun=model.set_z_get_kl,\n",
    "        input_par=prior_perturbation.model.global_vb_params,\n",
    "        output_par=moment_model.moment_params,\n",
    "        hyper_par=prior_perturbation.epsilon_param,\n",
    "        input_to_output_converter=moment_model.set_moments,\n",
    "        optimal_input_par=best_param_0,\n",
    "        objective_hessian=kl_hessian_0,\n",
    "        hyper_par_objective_fun=prior_perturbation.get_e_log_perturbation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_perturbation.get_e_log_perturbation()\n",
    "np.linalg.norm(epsilon_sensitivity.get_dinput_dhyper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit with perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = prior_perturbation.epsilon_param.get()\n",
    "print('Epsilon: ', epsilon)\n",
    "\n",
    "best_param_phi_pred = \\\n",
    "    epsilon_sensitivity.predict_input_par_from_hyperparameters(epsilon)\n",
    "output_phi_pred = epsilon_sensitivity.predict_output_par_from_hyperparameters(\n",
    "    epsilon, linear=True)\n",
    "\n",
    "output_phi = moment_model.set_and_get_moments_from_free_par(best_param_phi)\n",
    "output_0 = moment_model.set_and_get_moments_from_free_par(best_param_0)\n",
    "\n",
    "print('Predicted differences: ', np.linalg.norm(best_param_phi_pred - best_param_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Then fit with the perturbation.\n",
    "prior_perturbation.set_epsilon(1.0)\n",
    "print(prior_perturbation.epsilon_param)\n",
    "best_param_phi, converged, x_conv, f_conv, grad_conv, obj_opt, opt_results = \\\n",
    "    opt_lib.repeatedly_optimize(\n",
    "        objective=prior_perturbation.objective,\n",
    "        optimization_fun=\n",
    "            lambda x: gmm_utils.precondition_and_optimize(\n",
    "                prior_perturbation.objective, x),\n",
    "        init_x=best_param_phi_pred,\n",
    "        initial_optimization_fun=None,\n",
    "        keep_intermediate_optimizations=True)\n",
    "\n",
    "print('Done. Converged: ', converged)\n",
    "\n",
    "print('This is nonzero if phi did anything:', np.linalg.norm(best_param_phi - best_param_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Epsilon:', epsilon)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(best_param_phi - best_param_0, best_param_phi_pred - best_param_0, 'k.')\n",
    "plt.plot(best_param_phi - best_param_0, best_param_phi - best_param_0, 'r')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(output_phi - output_0, output_phi_pred - output_0, 'k.')\n",
    "plt.plot(output_phi - output_0, output_phi - output_0, 'r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
