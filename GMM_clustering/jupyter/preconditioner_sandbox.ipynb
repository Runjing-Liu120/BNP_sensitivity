{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rliu/anaconda3/envs/bnp_sensitivity/lib/python3.8/site-packages/autograd/core.py:290: UserWarning: \n",
      "The defvjp method is deprecated. See the update guide and tutorial:\n",
      "https://github.com/HIPS/autograd/blob/master/docs/updateguide.md\n",
      "https://github.com/HIPS/autograd/blob/master/docs/tutorial.md\n",
      "  warnings.warn(deprecation_msg)\n"
     ]
    }
   ],
   "source": [
    "import autograd\n",
    "\n",
    "import autograd.numpy as np\n",
    "\n",
    "import autograd.scipy as sp\n",
    "\n",
    "from bnpmodeling_runjingdev.modeling_lib import my_slogdet3d\n",
    "\n",
    "import bnpgmm_runjingdev.gmm_clustering_lib as gmm_lib\n",
    "import bnpgmm_runjingdev.gmm_preconditioner_lib as precond_lib\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import paragami\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check log-partition function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.random.randn(dim)\n",
    "info = np.random.randn(dim, dim)\n",
    "info = np.dot(info, info.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get paragami objects\n",
    "mvn_params_paragami, mvn_nat_params_paragami = \\\n",
    "    precond_lib.get_mvn_paragami_objects(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of parameters\n",
    "mvn_params_dict = mvn_params_paragami.random()\n",
    "mvn_params_dict['mean'] = mean\n",
    "mvn_params_dict['info'] = info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector of free canonical parameters\n",
    "mvn_free_params = mvn_params_paragami.flatten(mvn_params_dict, free = True)\n",
    "\n",
    "# vector of natural parameters\n",
    "nat_vec = precond_lib.get_nat_vec(mvn_free_params, mvn_params_paragami, mvn_nat_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0981180455136788"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precond_lib.get_mvn_log_partition(nat_vec, mvn_nat_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get gradient of log partition function\n",
    "get_grad_log_part = autograd.grad(precond_lib.get_mvn_log_partition)\n",
    "grad_log_part = get_grad_log_part(nat_vec, mvn_nat_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold gradient into dictionary\n",
    "grad_log_part_folded = mvn_params_paragami.fold(grad_log_part, free = False, validate_value = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get expectations of sufficient statistics\n",
    "e_x = mean\n",
    "e_x2 = np.linalg.inv(info) + np.einsum('i, j -> ij', mean, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check they match with gradient of log partition\n",
    "np.abs(e_x - grad_log_part_folded['mean']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.494005416219807e-16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(-e_x2 - grad_log_part_folded['info']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Fisher information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fishers_info = precond_lib.get_fishers_info(mvn_free_params, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a slightly different way to get the fishers info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dA / deta, eta being the natural pameters\n",
    "get_dA_deta = autograd.grad(precond_lib.get_mvn_log_partition)\n",
    "dA_deta = get_dA_deta(nat_vec, mvn_nat_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_partition_free_canon(mvn_free_param, mvn_params_paragami, mvn_nat_params_paragami): \n",
    "    # this is A(eta(theta)), where eta(theta) is the natural parameters as a function of the \n",
    "    # free canonical parameters \n",
    "    \n",
    "    nat_vec = precond_lib.get_nat_vec(mvn_free_param, mvn_params_paragami, mvn_nat_params_paragami)\n",
    "    return precond_lib.get_mvn_log_partition(nat_vec, mvn_nat_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dA2_dtheta2 = autograd.hessian(get_log_partition_free_canon)\n",
    "dA2_dtheta2 = get_dA2_dtheta2(mvn_free_params, mvn_params_paragami, mvn_nat_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is d^2 eta / dtheta^2\n",
    "get_deta2_dtheta2 = autograd.jacobian(precond_lib.get_jac_term, 0)\n",
    "deta2_dtheta2 = get_deta2_dtheta2(mvn_free_params, mvn_params_paragami, mvn_nat_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively the fishers info can be computed as \n",
    "# d^2A/dtheta^2 - dA/deta d^2eta / dtheta^2\n",
    "fishers_info2 = dA2_dtheta2 - np.einsum('j, jik -> ik', dA_deta, deta2_dtheta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9968028886505635e-15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(fishers_info - fishers_info2).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We also check against sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normal_logpdf(x, mean, info): \n",
    "    assert x.shape[1] == len(mean)\n",
    "    assert info.shape[0] == len(mean)\n",
    "    \n",
    "    diff = x - mean[None, :]\n",
    "    \n",
    "    cross = np.einsum('ni, ij -> nj', diff, info)\n",
    "    squared = np.einsum('nj, nj -> n', diff, cross)\n",
    "    \n",
    "    return -0.5 * squared + 0.5 * np.linalg.slogdet(info)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_q(x, mvn_free_params, mvn_params_paragami): \n",
    "    mvn_params_dict = mvn_params_paragami.fold(mvn_free_params, free = True)\n",
    "    \n",
    "    mean = mvn_params_dict['mean']\n",
    "    info = mvn_params_dict['info']\n",
    "    \n",
    "    return get_normal_logpdf(x, mean, info).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.multivariate_normal(mean, np.linalg.inv(info), 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.5016558211154554"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_log_q(x, mvn_free_params, mvn_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_est_fishers_info = autograd.hessian(get_log_q, argnum = 1)\n",
    "est_fishers_info = - get_est_fishers_info(x, mvn_free_params, mvn_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029448710329646577"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(fishers_info - est_fishers_info).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yet another way to get the fisher's info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_score_fun = autograd.grad(get_log_q, argnum = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "score_fun2_all = np.zeros((n_samples, len(mvn_free_params), len(mvn_free_params)))\n",
    "for i in range(n_samples): \n",
    "    score_fun = get_score_fun(x[i:(i+1)], mvn_free_params, mvn_params_paragami)\n",
    "    score_fun2_all[i] = np.einsum('i, j -> ij', score_fun, score_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_score_fun2 = score_fun2_all.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sd_score_fun2 = score_fun2_all.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "zscores = ((fishers_info - mean_score_fun2) / (sd_score_fun2 / np.sqrt(n_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(zscores.flatten(), bins = 100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OK, now we do it for the full set of vb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vb parameters\n",
    "k_approx = 30\n",
    "vb_params_dict, vb_params_paragami = gmm_lib.get_vb_params_paragami_object(dim, k_approx)\n",
    "vb_params_dict = vb_params_paragami.random()\n",
    "\n",
    "vb_free_params = vb_params_paragami.flatten(vb_params_dict, free = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "preconditioner = precond_lib.get_gmm_preconditioner(vb_free_params, vb_params_paragami).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "fishers_info = np.linalg.inv(preconditioner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check cluster parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(k_approx):\n",
    "    bool_dict = vb_params_paragami.empty_bool(False)\n",
    "    bool_dict['cluster_params']['centroids'][:, k] = True\n",
    "    bool_dict['cluster_params']['cluster_info'][k] = True\n",
    "\n",
    "    # get indices\n",
    "    indx_cluster_params_k = vb_params_paragami.flat_indices(bool_dict, free = True)\n",
    "    \n",
    "    # get free parameters for this cluster\n",
    "    mvn_params_dict['mean'] = vb_params_dict['cluster_params']['centroids'][:, k]\n",
    "    mvn_params_dict['info'] = vb_params_dict['cluster_params']['cluster_info'][k]\n",
    "    mvn_free_params_k = mvn_params_paragami.flatten(mvn_params_dict, free = True)\n",
    "    \n",
    "    assert (mvn_free_params_k == vb_free_params[indx_cluster_params_k]).all()\n",
    "    \n",
    "    # get fisher's info \n",
    "    fishers_info_k = precond_lib.get_fishers_info(mvn_free_params_k, dim)\n",
    "    \n",
    "    # compare with giant fisher's info matrix\n",
    "    for i in range(len(indx_cluster_params_k)): \n",
    "        for j in range(len(indx_cluster_params_k)): \n",
    "            assert np.abs(fishers_info[indx_cluster_params_k[i], indx_cluster_params_k[j]] - \n",
    "                          fishers_info_k[i, j]).max() < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_manual_fishers_info(free_params): \n",
    "    assert len(free_params) == 2\n",
    "    return np.array([[np.exp(free_params[1]), 0], [0, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(k_approx - 1):\n",
    "    bool_dict = vb_params_paragami.empty_bool(False)\n",
    "    bool_dict['stick_params']['stick_propn_mean'][k] = True\n",
    "    bool_dict['stick_params']['stick_propn_info'][k] = True\n",
    "\n",
    "    # get indices\n",
    "    indx_cluster_params_k = vb_params_paragami.flat_indices(bool_dict, free = True)\n",
    "    \n",
    "    fishers_info_k = get_manual_fishers_info(vb_free_params[indx_cluster_params_k])\n",
    "    \n",
    "    # compare with giant fisher's info matrix\n",
    "    for i in range(len(indx_cluster_params_k)): \n",
    "        for j in range(len(indx_cluster_params_k)): \n",
    "            assert np.abs(fishers_info[indx_cluster_params_k[i], indx_cluster_params_k[j]] - \n",
    "                          fishers_info_k[i, j]).max() < 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnp_sensitivity",
   "language": "python",
   "name": "bnp_sensitivity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
