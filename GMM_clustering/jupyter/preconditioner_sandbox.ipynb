{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rliu/anaconda3/envs/bnp_sensitivity/lib/python3.8/site-packages/autograd/core.py:290: UserWarning: \n",
      "The defvjp method is deprecated. See the update guide and tutorial:\n",
      "https://github.com/HIPS/autograd/blob/master/docs/updateguide.md\n",
      "https://github.com/HIPS/autograd/blob/master/docs/tutorial.md\n",
      "  warnings.warn(deprecation_msg)\n"
     ]
    }
   ],
   "source": [
    "import autograd\n",
    "\n",
    "import autograd.numpy as np\n",
    "\n",
    "import autograd.scipy as sp\n",
    "\n",
    "from bnpmodeling_runjingdev.modeling_lib import my_slogdet3d\n",
    "\n",
    "import bnpgmm_runjingdev.gmm_clustering_lib as gmm_lib\n",
    "import bnpgmm_runjingdev.gmm_preconditioner_lib as precond_lib\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import paragami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check log-partition function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.random.randn(dim)\n",
    "info = np.random.randn(dim, dim)\n",
    "info = np.dot(info, info.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get paragami objects\n",
    "mvn_params_paragami, mvn_nat_params_paragami = \\\n",
    "    precond_lib.get_mvn_paragami_objects(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of parameters\n",
    "mvn_params_dict = mvn_params_paragami.random()\n",
    "mvn_params_dict['mean'] = mean\n",
    "mvn_params_dict['info'] = info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector of free canonical parameters\n",
    "mvn_free_params = mvn_params_paragami.flatten(mvn_params_dict, free = True)\n",
    "\n",
    "# vector of natural parameters\n",
    "nat_vec = precond_lib.get_nat_vec(mvn_free_params, mvn_params_paragami, mvn_nat_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0435665952180575"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precond_lib.get_mvn_log_partition(nat_vec, mvn_nat_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get gradient of log partition function\n",
    "get_grad_log_part = autograd.grad(precond_lib.get_mvn_log_partition)\n",
    "grad_log_part = get_grad_log_part(nat_vec, mvn_nat_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold gradient into dictionary\n",
    "grad_log_part_folded = mvn_params_paragami.fold(grad_log_part, free = False, validate_value = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get expectations of sufficient statistics\n",
    "e_x = mean\n",
    "e_x2 = np.linalg.inv(info) + np.einsum('i, j -> ij', mean, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1102230246251565e-16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check they match with gradient of log partition\n",
    "np.abs(e_x - grad_log_part_folded['mean']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.885780586188048e-16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(-e_x2 - grad_log_part_folded['info']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Fisher information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fishers_info = precond_lib.get_fishers_info(mvn_free_params, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a slightly different way to get the fishers info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dA / deta, eta being the natural pameters\n",
    "get_dA_deta = autograd.grad(precond_lib.get_mvn_log_partition)\n",
    "dA_deta = get_dA_deta(nat_vec, mvn_nat_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_partition_free_canon(mvn_free_param, mvn_params_paragami, mvn_nat_params_paragami): \n",
    "    # this is A(eta(theta)), where eta(theta) is the natural parameters as a function of the \n",
    "    # free canonical parameters \n",
    "    \n",
    "    nat_param = nat_vec = precond_lib.get_nat_vec(mvn_free_param, mvn_params_paragami, mvn_nat_params_paragami)\n",
    "    return precond_lib.get_mvn_log_partition(nat_vec, mvn_nat_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dA2_dtheta2 = autograd.hessian(get_log_partition_free_canon)\n",
    "dA2_dtheta2 = get_dA2_dtheta2(mvn_free_params, mvn_params_paragami, mvn_nat_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is d^2 eta / dtheta\n",
    "get_deta2_dtheta2 = autograd.jacobian(precond_lib.get_jac_term, 0)\n",
    "deta2_dtheta2 = get_deta2_dtheta2(mvn_free_params, mvn_params_paragami, mvn_nat_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively the fishers info can be computed as \n",
    "# d^2A/dtheta^2 - dA/deta d^2eta / dtheta^2\n",
    "fishers_info2 = dA2_dtheta2 - np.einsum('j, jik -> ik', dA_deta, deta2_dtheta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1086244689504383e-15"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(fishers_info - fishers_info2).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We also check against sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normal_logpdf(x, mean, info): \n",
    "    assert x.shape[1] == len(mean)\n",
    "    assert info.shape[0] == len(mean)\n",
    "    \n",
    "    diff = x - mean[None, :]\n",
    "    \n",
    "    cross = np.einsum('ni, ij -> nj', diff, info)\n",
    "    squared = np.einsum('nj, nj -> n', diff, cross)\n",
    "    \n",
    "    return -0.5 * squared + 0.5 * np.linalg.slogdet(info)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_q(x, mvn_free_params, mvn_params_paragami): \n",
    "    mvn_params_dict = mvn_params_paragami.fold(mvn_free_params, free = True)\n",
    "    \n",
    "    mean = mvn_params_dict['mean']\n",
    "    info = mvn_params_dict['info']\n",
    "    \n",
    "    return get_normal_logpdf(x, mean, info).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.multivariate_normal(mean, np.linalg.inv(info), 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.208378139780283"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_log_q(x, mvn_free_params, mvn_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_est_fishers_info = autograd.hessian(get_log_q, argnum = 1)\n",
    "est_fishers_info = - get_est_fishers_info(x, mvn_free_params, mvn_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_funs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0211458253964827"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(fishers_info - est_fishers_info).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OK, now we do it for the full set of vb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vb parameters\n",
    "k_approx = 30\n",
    "vb_params_dict, vb_params_paragami = gmm_lib.get_vb_params_paragami_object(dim, k_approx)\n",
    "vb_params_dict = vb_params_paragami.random()\n",
    "\n",
    "vb_free_params = vb_params_paragami.flatten(vb_params_dict, free = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gmm_preconditioner(vb_free_params, vb_params_paragami):\n",
    "    preconditioner = sparse.lil_matrix((len(vb_free_params), len(vb_free_params)))\n",
    "    \n",
    "    bool_dict = vb_params_paragami.empty_bool(False)\n",
    "    \n",
    "    k_approx = bool_dict['cluster_params']['centroids'].shape[1]\n",
    "    dim = bool_dict['cluster_params']['centroids'].shape[0]\n",
    "    \n",
    "    # get preconditioners for cluster parameters \n",
    "    for k in range(k_approx): \n",
    "        bool_dict['cluster_params']['centroids'][:, k] = True\n",
    "        bool_dict['cluster_params']['cluster_info'][k] = True\n",
    "        \n",
    "        # get indices\n",
    "        indx_cluster_params_k = vb_params_paragami.flat_indices(bool_dict, free = True)\n",
    "        indx_product = np.array(list(product(indx_cluster_params_k, indx_cluster_params_k)))\n",
    "        \n",
    "        # get free parameters\n",
    "        free_params_cluster_params_k = vb_free_params[indx_cluster_params_k]\n",
    "        \n",
    "        # fisher information \n",
    "        fishers_info_cluster_params_k = precond_lib.get_fishers_info(free_params_cluster_params_k, dim)\n",
    "        \n",
    "        # update preconditioner\n",
    "        preconditioner[indx_product[:, 0], indx_product[:, 1]] = \\\n",
    "            np.linalg.inv(fishers_info_cluster_params_k).flatten()\n",
    "        \n",
    "        \n",
    "        # reset dictionary \n",
    "        bool_dict = vb_params_paragami.empty_bool(False)\n",
    "    \n",
    "    # get preconditioners for stick parameters \n",
    "    for k in range(k_approx - 1): \n",
    "        bool_dict['stick_params']['stick_propn_mean'][k] = True\n",
    "        bool_dict['stick_params']['stick_propn_info'][k] = True\n",
    "        \n",
    "        # get indices\n",
    "        indx_stick_params_k = vb_params_paragami.flat_indices(bool_dict, free = True)\n",
    "        indx_product = np.array(list(product(indx_stick_params_k, indx_stick_params_k)))\n",
    "        \n",
    "        # get free parameters\n",
    "        free_params_stick_params_k = vb_free_params[indx_stick_params_k]\n",
    "        \n",
    "        # fisher information \n",
    "        free_params_stick_params_k = precond_lib.get_fishers_info(free_params_stick_params_k, 1)\n",
    "        \n",
    "        # update preconditioner\n",
    "        preconditioner[indx_product[:, 0], indx_product[:, 1]] = \\\n",
    "            np.linalg.inv(free_params_stick_params_k).flatten()\n",
    "        \n",
    "        \n",
    "        # reset dictionary \n",
    "        bool_dict = vb_params_paragami.empty_bool(False)\n",
    "\n",
    "    return preconditioner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<478x478 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5996 stored elements in List of Lists format>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gmm_preconditioner(vb_free_params, vb_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('cluster_params',\n",
       "              OrderedDict([('centroids',\n",
       "                            array([[ True, False, False, False, False, False, False, False, False,\n",
       "                                    False, False, False, False, False, False, False, False, False,\n",
       "                                    False, False, False, False, False, False, False, False, False,\n",
       "                                    False, False, False],\n",
       "                                   [ True, False, False, False, False, False, False, False, False,\n",
       "                                    False, False, False, False, False, False, False, False, False,\n",
       "                                    False, False, False, False, False, False, False, False, False,\n",
       "                                    False, False, False],\n",
       "                                   [ True, False, False, False, False, False, False, False, False,\n",
       "                                    False, False, False, False, False, False, False, False, False,\n",
       "                                    False, False, False, False, False, False, False, False, False,\n",
       "                                    False, False, False],\n",
       "                                   [ True, False, False, False, False, False, False, False, False,\n",
       "                                    False, False, False, False, False, False, False, False, False,\n",
       "                                    False, False, False, False, False, False, False, False, False,\n",
       "                                    False, False, False]])),\n",
       "                           ('cluster_info',\n",
       "                            array([[[ True,  True,  True,  True],\n",
       "                                    [ True,  True,  True,  True],\n",
       "                                    [ True,  True,  True,  True],\n",
       "                                    [ True,  True,  True,  True]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]],\n",
       "                            \n",
       "                                   [[False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False],\n",
       "                                    [False, False, False, False]]]))])),\n",
       "             ('stick_params',\n",
       "              OrderedDict([('stick_propn_mean',\n",
       "                            array([False, False, False, False, False, False, False, False, False,\n",
       "                                   False, False, False, False, False, False, False, False, False,\n",
       "                                   False, False, False, False, False, False, False, False, False,\n",
       "                                   False, False])),\n",
       "                           ('stick_propn_info',\n",
       "                            array([False, False, False, False, False, False, False, False, False,\n",
       "                                   False, False, False, False, False, False, False, False, False,\n",
       "                                   False, False, False, False, False, False, False, False, False,\n",
       "                                   False, False]))]))])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "preconditioner = sparse.lil_matrix((len(vb_free_params), len(vb_free_params)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_dict = vb_params_paragami.empty_bool(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_dict['cluster_params']['centroids'][:, k] = True\n",
    "bool_dict['cluster_params']['cluster_info'][k] = True\n",
    "\n",
    "indx_cluster_params_k = vb_params_paragami.flat_indices(bool_dict, free = True)\n",
    "free_params_cluster_params_k = vb_free_params[indx_cluster_params_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "fishers_info_cluster_params_k = precond_lib.get_fishers_info(free_params_cluster_params_k, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx_product = np.array(list(product(indx_cluster_params_k, indx_cluster_params_k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "preconditioner[indx_product[:, 0], indx_product[:, 1]] = np.linalg.inv(fishers_info_cluster_params_k).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<478x478 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 196 stored elements in List of Lists format>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preconditioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9344494 , 0.04248797, 0.33043887, 0.2112118 , 0.90321367,\n",
       "       0.81396135, 0.32261851, 0.89816291, 0.32479739, 0.40991716,\n",
       "       0.63988727, 0.36597507, 0.00829408, 0.64773205])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "free_params_cluster_params_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_dict = vb_params_paragami.empty_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_dict = deepcopy(vb_params_dict)\n",
    "bool_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_indx = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fishers_info_k = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 2],\n",
       "       [1, 3],\n",
       "       [2, 1],\n",
       "       [2, 2],\n",
       "       [2, 3],\n",
       "       [3, 1],\n",
       "       [3, 2],\n",
       "       [3, 3]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(product([1, 2, 3], [1, 2, 3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "k_approx = mean.shape[0]\n",
    "dim = mean.shape[1]\n",
    "\n",
    "# get paragami objects\n",
    "mvn_params_paragami, mvn_nat_params_paragami = \\\n",
    "    get_mvn_paragami_objects(k_approx, dim)\n",
    "\n",
    "# dictionary of parameters\n",
    "mvn_params_dict = mvn_params_paragami.random()\n",
    "mvn_params_dict['mean'] = mean\n",
    "mvn_params_dict['info'] = info\n",
    "\n",
    "# vector of parameters\n",
    "param_vec = mvn_params_paragami.flatten(mvn_params_dict, free = True)\n",
    "nat_vec = get_nat_vec(param_vec, mvn_params_paragami, mvn_nat_params_paragami)\n",
    "\n",
    "fishers_info = get_log_part_hess(nat_vec, mvn_nat_params_paragami)\n",
    "\n",
    "jac_term = get_jac_term(param_vec, mvn_params_paragami, mvn_nat_params_paragami)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fishers_info.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "jac_term.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_nat_vec(param_vec, mvn_params_paragami, mvn_nat_params_paragami): \n",
    "    \n",
    "    nat_params_dict = {}\n",
    "    \n",
    "    mvn_param_dict = mvn_params_paragami.fold(param_vec, free = False)\n",
    "    \n",
    "    mean = mvn_param_dict['mean']\n",
    "    info = mvn_param_dict['info']\n",
    "        \n",
    "    nat_params_dict['nat1'] = np.einsum('kij, kj -> ki', info, mean)\n",
    "    nat_params_dict['neg_nat2'] = 0.5 * info\n",
    "    \n",
    "    return mvn_nat_params_paragami.flatten(nat_params_dict, free = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_mvn_log_partition(nat_vec, mvn_nat_params_paragami): \n",
    "    \n",
    "    nat_params_dict = mvn_nat_params_paragami.fold(nat_vec, free = False)\n",
    "    \n",
    "    nat1 = nat_params_dict['nat1']\n",
    "    neg_nat2 = nat_params_dict['neg_nat2']\n",
    "    \n",
    "    nat2_inv = np.linalg.inv(-neg_nat2)\n",
    "\n",
    "    nat2_inv_nat1 = np.einsum('kij, kj -> ki', nat2_inv, nat1)\n",
    "    squared_term = np.einsum('ki, ki -> k', nat1, nat2_inv_nat1)\n",
    "\n",
    "    return (- 0.25 * squared_term - 0.5 * my_slogdet3d(2 * neg_nat2)[1]).sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "get_jac_term = autograd.jacobian(get_nat_vec, 0)\n",
    "get_log_part_hess = autograd.hessian(get_mvn_log_partition, 0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_mvn_paragami_objects(k_approx, dim):\n",
    "    mvn_nat_params_paragami = paragami.PatternDict()\n",
    "    mvn_nat_params_paragami['nat1'] = \\\n",
    "        paragami.NumericArrayPattern(shape=(k_approx, dim))\n",
    "    mvn_nat_params_paragami['neg_nat2'] = \\\n",
    "        paragami.pattern_containers.PatternArray(array_shape = (k_approx, ), \\\n",
    "                    base_pattern = paragami.PSDSymmetricMatrixPattern(size=dim))\n",
    "    \n",
    "    mvn_params_paragami = paragami.PatternDict()\n",
    "    mvn_params_paragami['mean'] = \\\n",
    "        paragami.NumericArrayPattern(shape=(k_approx, dim))\n",
    "    mvn_params_paragami['info'] = \\\n",
    "        paragami.pattern_containers.PatternArray(array_shape = (k_approx, ), \\\n",
    "                    base_pattern = paragami.PSDSymmetricMatrixPattern(size=dim))\n",
    "    \n",
    "    return mvn_params_paragami, mvn_nat_params_paragami"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_fishers_info(mean, info): \n",
    "    assert mean.shape[0] == info.shape[0]\n",
    "    assert mean.shape[1] == info.shape[1]\n",
    "    \n",
    "    k_approx = mean.shape[0]\n",
    "    dim = mean.shape[1]\n",
    "    \n",
    "    # get paragami objects \n",
    "    mvn_params_paragami, mvn_nat_params_paragami = \\\n",
    "        get_mvn_paragami_objects(k_approx, dim)\n",
    "    \n",
    "    # dictionary of parameters \n",
    "    mvn_params_dict = mvn_params_paragami.random()\n",
    "    mvn_params_dict['mean'] = mean\n",
    "    mvn_params_dict['info'] = info\n",
    "    \n",
    "    # vector of parameters \n",
    "    param_vec = mvn_params_paragami.flatten(mvn_params_dict, free = False)\n",
    "    nat_vec = get_nat_vec(param_vec, mvn_params_paragami, mvn_nat_params_paragami)\n",
    "    \n",
    "    fishers_info = get_log_part_hess(nat_vec, mvn_nat_params_paragami)\n",
    "    \n",
    "    jac_term = get_jac_term(nat_vec, mvn_params_paragami, mvn_nat_params_paragami)\n",
    "    \n",
    "    return np.dot(jac_term, np.dot(fishers_info, jac_term))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "foo = get_fishers_info(vb_params_dict['cluster_params']['centroids'].transpose(), \n",
    "                vb_params_dict['cluster_params']['cluster_info'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "get_fishers_info(vb_params_dict['stick_params']['stick_propn_mean'][:, None], \n",
    "                    vb_params_dict['stick_params']['stick_propn_info'][:, None, None])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_mvn_log_partition(mean, info): \n",
    "    info_mean = np.einsum('kij, kj -> ki', info, mean)\n",
    "    mean_info_mean = np.einsum('ki, kj -> k', mean, info_mean)\n",
    "    \n",
    "    return (0.5 * mean_info_mean + 0.5 * my_slogdet3d(info)[1]).mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_log_partition_free(vb_params_free, vb_params_paragami, use_logitnormal_sticks = True): \n",
    "    vb_params_dict = vb_params_paragami.fold(vb_params_free, free = True)\n",
    "    \n",
    "    cluster_log_part = get_mvn_log_partition(vb_params_dict['cluster_params']['centroids'].transpose(), \n",
    "                                            vb_params_dict['cluster_params']['cluster_info'])\n",
    "    \n",
    "    if use_logitnormal_sticks: \n",
    "        stick_log_part = get_mvn_log_partition(vb_params_dict['stick_params']['stick_propn_mean'][:, None], \n",
    "                                            vb_params_dict['stick_params']['stick_propn_info'][:, None, None])\n",
    "    \n",
    "    else: \n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    return cluster_log_part + stick_log_part"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "get_fishers_info = autograd.hessian(get_log_partition_free, 0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vb_params_free = vb_params_paragami.flatten(vb_params_dict, free = True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "get_log_partition_free(vb_params_free, vb_params_paragami)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "get_fishers_info = autograd.hessian(get_mvn_log_partition_free, 0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "get_fishers_info(vb_params_free, vb_params_paragami)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "NotImplementedError()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cluster_params_paragami = vb_params_paragami['cluster_params']\n",
    "cluster_params_free = cluster_params_paragami.flatten(vb_params_dict['cluster_params'], free = True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "get_mvn_log_partition_free(cluster_params_free, cluster_params_paragami)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "get_fishers_info = autograd.hessian(get_mvn_log_partition_free, 0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "get_fishers_info(cluster_params_free, cluster_params_paragami)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnp_sensitivity",
   "language": "python",
   "name": "bnp_sensitivity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
