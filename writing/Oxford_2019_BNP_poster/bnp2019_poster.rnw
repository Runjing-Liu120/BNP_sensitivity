\documentclass[a0,plainsections,30pt]{sciposter}

\usepackage{graphicx}
%\usepackage{subfig}
%\usepackage{subfigure}
%\usepackage{caption}

%\usepackage{epstopdf, graphicx}
%\usepackage{booktabs,dcolumn}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{bbm}
%\usepackage{hhline}
%\usepackage{multicol}
\usepackage[authoryear]{natbib}
%\usepackage{hyperref} % WTF, this causes a "caption outside of float" error

\setlength{\columnseprule}{0pt}
%\usepackage{boxedminipage}

\newcommand{\widgraph}[2]{\includegraphics[keepaspectratio,width=#1]{#2}}

\newcommand{\Rbb}{\mathbb{R}}
\newcommand{\Expect}{\mathbb{E}}
\newcommand{\Expecthat}{\hat{\mathbb{E}}}
\newcommand{\Var}{\text{Var}}
\newcommand{\Cov}{\text{Cov}}
\newcommand{\vbfamily}{\mathcal{Q}}
\newcommand{\etaopt}{\eta^{*}}
\newcommand{\etazopt}{\eta_z^{*}}
\newcommand{\etathetaopt}{\eta_\theta^{*}}
%\newcommand{\qopt}{q^{*}}
\newcommand{\targethat}{\hat{g}}
\newcommand{\QExpect}
{\Expect_{q\left(\theta, z \vert \eta_\theta, \etazopt(\eta_\theta)\right)}}
\newcommand{\atzero}{\Big\rvert_{\eta_\theta = \etathetaopt, \epsilon = 0}}
\newcommand{\etathetalin}{\eta_\theta^{LIN}}

\newcommand{\targetexpectation}{\Expect_{q_{\eta^*}}
\left[\#\{\substack{\text{distinct clusters}\\\text{in new dataset}}\} \right]}

\usepackage[framemethod=TikZ, xcolor=RGB]{mdframed}

\definecolor{mydarkblue}{rgb}{0,.06,.5}
\definecolor{mydarkred}{rgb}{.5,0,.1}
\definecolor{myroyalblue}{rgb}{0,.1,.8}

\usepackage{sectsty}
\sectionfont{\color{mydarkblue}\centering\LARGE\bf}

\mdfdefinestyle{MyFrame}{%
    linecolor=mydarkblue,
    outerlinewidth=2pt,
    roundcorner=20pt,
    innertopmargin=10pt,
    innerbottommargin=10pt,
    innerrightmargin=10pt,
    innerleftmargin=10pt,
    backgroundcolor=blue!10}


\title{\textcolor{mydarkblue}{
Evaluating Sensitivity to the Stick Breaking Prior in Bayesian Nonparametrics
}}

\author{Ryan Giordano\textsuperscript{2*} \quad
Runjing Liu\textsuperscript{1*} \quad
Michael I. Jordan\textsuperscript{1} \quad
Tamara Broderick\textsuperscript{2} \\
{\large\normalfont\textsuperscript{*}
These authors contributed equally}\quad
 {\large\normalfont\textsuperscript{1}
 Department of Statistics, UC Berkeley \quad \textsuperscript{2} CSAIL, MIT}
 }

\leftlogo[1]{static_images/logo_left.png}
\rightlogo[1]{static_images/logo_right2.png}

% Set the color used for the section headings here
\definecolor{SectionCol}{rgb}{0,.06,.5}
\definecolor{lightblue}{rgb}{0.8,0.8,1}

% Set some fbox commands line width and the color we use in the f boxes
\setlength{\fboxrule}{.09cm}
\definecolor{boxcolor}{rgb}{1,1,1}
\definecolor{innerboxcolor}{rgb}{.9,.94,.98}

% Math macros
\newcommand{\eq}[1]{Eq.~(\ref{eq:#1})}

\newcommand{\kl}{\textrm{KL}}
\newcommand{\mbe}{\mathbb{E}}
\newcommand{\mbeq}{\mathbb{E}_{q}}
\newcommand{\var}{\textrm{Var}}
\newcommand{\cov}{\textrm{Cov}}
\newcommand{\iid}{\stackrel{iid}{\sim}}
\newcommand{\indep}{\stackrel{indep}{\sim}}
\newcommand{\gauss}{\mathcal{N}} % Gaussian distribution

\DeclareMathOperator*{\argmin}{arg\,min}

% my added commands
\usepackage{etoolbox}
% \BeforeBeginEnvironment{figure}{\vskip-2ex}
% \AfterEndEnvironment{figure}{\vskip-1ex}

% Fiddle with the margin
\addtolength{\topmargin}{-0.5in}
% \addtolength{\topmargin}{-0.875in}
\addtolength{\textheight}{1in}
\begin{document}
\conference{BNP 2019}

\setlength{\parskip}{0.25em}

\maketitle

\vspace{-1in}


<<initialization, echo=FALSE, message=FALSE, results='asis'>>=
library(tidyverse)
knitr_debug <- FALSE
source("./R_graphs/Initialize.R")

# Common graphs library
source("./R_graphs/CommonGraphs.R")

# This file is produced by R_graphs/data/iris_data/make_knitr_dataset.R.
iris_data <- LoadIntoEnvironment(
    file.path(data_path, "iris_data/iris_data_for_knitr.Rdata"))

# Puts genomics_data in the environment.
source("./R_graphs/ProcessGenomicsData.R")

# Turn off caching if you need to regenerate any of the R code.
knitr_debug <- FALSE # Set to true to see error output
cache_knitr <- FALSE # Set to true to cache knitr output for this analysis.
@


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% FIRST COLUMN
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\columnbreak

\begin{minipage}[t]{0.45\textwidth}

\begin{mdframed}[style=MyFrame]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%
\section*{Overview}
\vspace{-0.3in}
%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{itemize}
\item Researchers often want to estimate the number of distinct clusters
that would be present in a new dataset.

\item A variational Bayes (VB) approximation to a Bayesian nonparametric (BNP)
model makes inferring the number of clusters amenable to Bayesian inference.
%We approximate the exact posterior with variational Bayes (VB).

\item \textbf{Question}: How sensitive are the
VB approximation and the resulting inferences to BNP model choices?

\item \textbf{Problem}: Re-running VB for multiple model choices is expensive.

\item \textbf{We propose}: A local approximation to efficiently
estimate BNP sensitivity from a single run of VB, avoiding
expensive refitting.

%\item We evaluate sensitivity to parametric and functional perturbations.
\end{itemize}
\end{mdframed}
\vspace{-0.7in}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Model and inference }
\vspace{-0.3in}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% In the setting of \textbf{unsupervised clustering}, suppose we wish to know how
% many distinct clusters we'd find in a new dataset with the same distribution as
% observed data.  We will answer with BNP.

The \textbf{Dirichlet process} is a popular Bayesian nonparametric
(BNP) model used for clustering.  A stick-breaking representation uses
a distribution on sticks $\{\nu_k\}$ to induce a prior on component
probabilities $\{\pi_k\}$.

\begin{figure}
\caption{The Dirichlet stick-breaking process with $\nu_k \sim \mathrm{Beta}(1, \alpha)$.}
\centering
\includegraphics[width = 0.95\textwidth]{./static_images/DP_stick_breaking.png}
\end{figure}
%
%We approximate the true posterior using \textbf{variational Bayes} (VB).
%
\begin{itemize}
\item $\epsilon :=$ Any real-valued hyperparameter for the stick-breaking prior
    $p(\nu_k | \epsilon)$.
\item $\etaopt :=$ The optimal variational parameters.
\item $\targetexpectation :=$ The quantity we want to infer.
\end{itemize}

\begin{mdframed}[style=MyFrame]
VB inference defines a map:
%
\begin{gather*}
\textrm{Stick-breaking prior}
    \mapsto \textrm{VB approximation}
    \mapsto \textrm{Posterior expected \# clusters},\\
\textrm{i.e.,}\\
\epsilon
    \mapsto \etaopt
    \mapsto \targetexpectation.
\end{gather*}
\end{mdframed}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Parametric perturbation.} To stay within the class of Dirichlet
processes, we might take $\epsilon := \alpha - \alpha_0$ and $p(\nu_k | \alpha) :=
\mathrm{Beta}(\nu_k | 1, \alpha)$.

\textbf{Functional perturbation.} Suppose we are interested in the effect of
replacing the original beta prior $p_0(\nu_k) := \mathrm{Beta}(\nu_k | 1,
\alpha)$ with another distribution $p_1(\nu_k)$. Then we take $\epsilon :=
\delta$ in
%
\vspace{-0.3in}
\begin{align*}
p(\nu_k \vert \delta) \propto
    p_{0}(\nu_k)\left(\frac{p_1(\nu_k)}{p_0(\nu_k)}\right)^\delta.
\end{align*}
\vspace{-0.3in}

By using a multiplicative perturbation, the map $p_1 \mapsto \etaopt$ is
Fr\'{e}chet differentiable in the norm $\left\Vert p_1 / p_0
\right\Vert_\infty$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-0.3in}
\subsection*{Linear approximation}
\vspace{-0.2in}
%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Let $\epsilon=0$ represent the original prior at which we fit a VB
approximation.

\begin{mdframed}[style=MyFrame]
For any other $\epsilon \ne 0$ we approximate $\epsilon \mapsto \etaopt$ with
\begin{align*}
\eta^*(\epsilon)  &\approx  \eta^*(0) +
\frac{d \eta^*(\epsilon)}{d\epsilon^T}\Big|_{\epsilon=0} \epsilon.
\label{eq:linear_approx}
\end{align*}
We retain the non-linearities in $\etaopt \mapsto \targetexpectation$.
\end{mdframed}

\begin{itemize}
\item We can \textbf{automatically compute}
    the approximation
    using automatic differentiation \cite{giordano:2017:covariances}.
    %\cite{giordano:2017:covariances, maclaurin:2015:autograd}.
\item The approximation requires the
    \textbf{inverse Hessian of the VB objective}.
\item This is an application of \textbf{local Bayesian robustness}
\citep{gustafson:1996:localposterior}.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%
% \begin{center}
% \noindent\rule{0.95\textwidth}{1pt}
% \end{center}
% {\bf References}
%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \renewcommand{\section}[2]{}%
% \footnotesize{
%   \bibliographystyle{abbrv}
%   \bibliography{./references}
% }

\end{minipage}
\hfill \vrule \hfill
\begin{minipage}[t]{0.45\textwidth}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECOND COLUMN
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%
%\vspace{-0.3in}
\section*{Data}
\vspace{-0.3in}
%
\begin{minipage}[t]{0.49\textwidth}
%
\subsection*{Iris data}
For our first dataset, we discard species
information and cluster the 150 four-dimensional observations of the Fisher iris
dataset \citep{iris_data_anderson}.
The loadings on the first two principle components is shown
to the right.
%
\end{minipage}
%
\begin{minipage}[t]{0.49\textwidth}
<<iris_pca_cap, cache=FALSE>>=
SetImageSize(aspect_ratio=2.0 * base_aspect_ratio,
             image_width=0.5 * base_image_width)
@

<<iris_pca, cache=cache_knitr, fig.show='hold'>>=
ggplot(iris_data$iris_df) +
  geom_point(aes(x=PC1, y=PC2))
@
\end{minipage}
%

\vspace{1em}

\begin{minipage}[t]{0.49\textwidth}
%
\subsection*{Mouse data} For our second dataset, we use a publicly available
dataset of gene expression in mice \citep{shoemaker:2015:ultrasensitive} . We
smooth and center the 7000 gene expression time series and cluster the resulting
patterns.  A typical smoothed time series with uncertainty is shown to the
right.
%
\end{minipage}
%
\begin{minipage}[t]{0.49\textwidth}
\begin{figure}[!h]
\centering
\includegraphics[width = 0.95\textwidth]{./static_images/mouse_genes.png}
\end{figure}
\end{minipage}
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%
\vspace{-0.6in}
\section*{Results}
\vspace{-0.3in}

\textbf{Parametric perturbation.}
Vertical lines show the location of $\alpha_0$.

\vspace{0.05in}
%
<<fig_cap1, cache=FALSE>>=
fig_cap1 <- "Re-optimization vs approximation."
SetImageSize(aspect_ratio=1.0 * base_aspect_ratio)
@
<<param_sens_plot, cache=cache_knitr, fig.show='hold'>>=
results_df_1 <- filter(iris_data$results_df, !pred, pert=="alpha3")
results_df_2 <- filter(iris_data$results_df, !pred, pert=="alpha8")
results_df_3 <- filter(iris_data$results_df, !pred, pert=="alpha13")
grid.arrange(
    plot_parametric_sensitivity(results_df_1, alpha_0 = 3.0) +
      ggtitle('Iris data') +
        theme(legend.position = 'none', legend.title=element_blank()),
    plot_parametric_sensitivity(results_df_2, alpha_0 = 8.0) +
      ggtitle(' ') + theme(legend.position="none"),
    plot_parametric_sensitivity(results_df_3, alpha_0 = 13.0) +
      ggtitle(' ') + theme(legend.position="none"),
    ncol  = 3)
@

<<gene_param_sens_plot, cache=cache_knitr, fig.show='hold'>>=
grid.arrange(
    plot_parametric_sensitivity(
      genomics_data$processed_results %>%
        filter(!inflate, !alpha_increase, !functional),
      alpha_0=2.0) +
      ggtitle("Mouse data")  + theme(legend.position="none"),
  plot_parametric_sensitivity(
    genomics_data$processed_results %>%
      filter(!inflate, alpha_increase, !functional),
    alpha_0=2.0) +
    ggtitle(" ") + theme(legend.position=c(0.75, 0.65)),
    ncol=2
)
@

\textbf{Functional perturbation.} The first row shows the original prior
$p_0(\nu_k)$ and the functional perturbation $p_1(\nu_k)$.

\vspace{0.1in}
<<fig_cap2, cache=FALSE>>=
SetImageSize(aspect_ratio= 2.0 * base_aspect_ratio)
@
<<functional_sens_plot, cache=cache_knitr, fig.show='hold'>>=
iris_pert1 <- filter(iris_data$prior_pert_df, filename == "prior_pert1.csv")
iris_pert2 <- filter(iris_data$prior_pert_df, filename == "prior_pert2.csv")
iris_pred_pert1 <- filter(iris_data$results_df, pred, pert=="1")
iris_pred_pert2 <- filter(iris_data$results_df, pred, pert=="2")

gene_pred_pert <- filter(genomics_data$processed_results,
                         functional, !inflate)

grid.arrange(
    # First row --- include titles.
    plot_prior_perturbation(iris_pert1) +
        theme(legend.position = "None") +
        ggtitle("Iris data (a)"),

    plot_prior_perturbation(iris_pert2) +
        theme(legend.position = "None") +
        ggtitle("Iris data (b)"),

    plot_prior_perturbation(genomics_data$processed_pert_df) +
        theme(legend.position = c(0.45, 0.80)) +
        ggtitle("Mouse data"),

    # Second row --- results
    plot_parametric_sensitivity(iris_pred_pert1, xlabel=TeX("$\\delta$")) +
        theme(legend.position = "None"),

    plot_parametric_sensitivity(iris_pred_pert2, xlabel=TeX("$\\delta$")) +
        theme(legend.position =  "None"),

    plot_parametric_sensitivity(gene_pred_pert, xlabel=TeX("$\\delta$")) +
        theme(legend.position =  c(0.7, 0.8)),
    ncol=3
)
@

The approximation consistently \textbf{performs better when extraploating to
fewer clusters}.

\noindent\rule{0.95\textwidth}{1pt}

{\bf Contact and code: } rgiordano@berkeley.edu, runjing\_liu@berkeley.edu
%{\bf Code: } \newline
% \url{https://github.com/Runjing-Liu120/sensitivity_to_stick_breaking_in_BNP}{a}
% \url{https://github.com/rgiordan/vittles}{b}
{\color{blue} https://github.com/Runjing-Liu120/sensitivity\_to\_stick\_breaking\_in\_BNP}
{\color{blue} https://github.com/rgiordan/vittles}

% \begin{center}
% \noindent\rule{0.95\textwidth}{1pt}
% \end{center}
% \input{acknowledgements}

\end{minipage}\\

\begin{center}
\noindent\rule{0.95\textwidth}{1pt}
\end{center}
\input{acknowledgements}

\renewcommand{\section}[2]{}%
\footnotesize{
  \bibliographystyle{abbrv}
  \bibliography{./references}
}

\end{document}
