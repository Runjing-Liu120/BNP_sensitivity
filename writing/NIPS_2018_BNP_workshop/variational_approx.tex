%
\paragraph{Variational approximation.}
It is difficult to calculate the posterior $p\left(\nu, \mu, \Sigma, z \vert
y\right)$, both because the normalizing constant is intractable and because
$K=\infty$ in a true BNP represetation. In order to perform approximate
inference, we use a truncated VB approximation
\citep{blei:2006:dirichletbnp}. For compactness of notation, let $\theta =
\left(\nu, \mu, \Sigma\right)$ denote the collection of ``global'' parameters,
i.e., parameters whose values affect the data generating process of every
observation $y_n$.   Let $\delta\left(\cdot\right)$ denote a delta function. We
define a class of approximating distributions for VB as
%
\begin{align*}
\vbfamily := \Big\{ q:
q(\theta, z) = &
\left(\prod_{k=1}^{K}q\left(\nu_{k}\right)\delta\left(\mu_{k}\right)
    \delta\left(\Sigma_{k}\right)\right)
    \left(\prod_{n=1}^{150}q\left(z_{n}\right) \right)\textrm{, where } \\
q\left(\nu_{k}\right) =& \mathrm{Lognormal}\left(\nu_k\right) \textrm{ and }
q\left(z_n\right) = \mathrm{Multinomial}\left(z_n\right)
\Big\}
\end{align*}
%
The family $\vbfamily$ is parameterized by a finite-dimension vector containing
the locations of the delta functions and the parameters for the lognormal
distributions, which we denote by $\eta_\theta$, and the parameters for the
multinomial distributions, which we denote by $\eta_z$.
We write the combined parameters as $\eta=\left(\eta_\theta, \eta_z\right)$.
That is, $\eta$ is defined such that
%
$\vbfamily =
    \left\{q: q\left(\theta, z\right) =
            q\left(\theta, z \vert \eta \right) =
            q\left(\theta \vert \eta_\theta \right)
            q\left(z \vert \eta_z \right)
    \right\}.$
%
The variational approximation is then given by
%
\begin{align}
\etaopt = \argmin_{\eta} KL\left(
    q(\theta, z \vert \eta) \big\| p(\theta, z | y)
    \right). \label{eq:kl_objective}
\end{align}
%
It will be important later to note that it is easy to calculate
the optimal $\eta_z$ for a given $\eta_\theta$ because the model is
conjugate, i.e., $p\left(z \vert \theta, y\right)$ is multinomial,
and so is $q\left(z \vert \eta_z\right)$.  Specifically, there
exists an easily-calculated, closed form for
%
\begin{align}
\etazopt\left(\eta_\theta\right) = \argmin_{\eta_z}
    KL\left(
    q(\theta \vert \eta_\theta) q( z \vert \eta_z)
        \big\| p(\theta, z | y)
    \right).
\label{eq:z_update}
\end{align}
%

%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%


\paragraph{Target posterior quantity.}

Let $\qopt\left(\theta, z\right) = q\left(\theta, z \vert \etaopt\right)$.
We are interested in the inferred number of clusters present in the observed
data, which can be expressed as an expection with respect to
$q\left(z \vert \eta_z \right)$, and so as a function of
$\etathetaopt$ via the relation $\etazopt(\eta_\theta)$:
%
\begin{align}
g(\etathetaopt) &:=
\Expect_{\qopt} \left[ \#\{\text{distinct clusters}\} \right]  =
\Expect_{q(z \vert \etazopt(\eta_\theta))} \left[
    \sum_{k=1}^K \prod_{n=1}^N \mathbb{I}\{z_n = k\} \right]
    \label{eq:expected_num_clusters}
\end{align}
%
For a given variational distribtion, $g(\etathetaopt)$ can be computed with
Monte-Carlo draws of the cluster indicators. In general, the mapping
that comprises $g(\etathetaopt)$,
%
\begin{align}
\eta_\theta \mapsto
\etazopt\left(\eta_\theta\right) \mapsto
\textrm{A draw from }z \sim q(z \vert \etazopt) \mapsto
\sum_{k=1}^K \prod_{n=1}^N \mathbb{I}\{z_n = k\},
\end{align}
%
is highly non-linear.  However, it is also easily and quickly computed.
