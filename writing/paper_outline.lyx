#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\basepost}[1][\theta]{p\left(#1\vert X\right)}
{p\left(#1\vert X\right)}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\baseprior}[1][\theta]{p\left(#1\right)}
{p\left(#1\right)}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\post}[2][\theta][\alpha]{p\left(#1\vert X,#2\right)}
{p\left(#1\vert X,#2\right)}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\qpost}[2][\theta][\eta^{*}]{q\left(#1;#2\right)}
{q\left(#1;#2\right)}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\logpert}[2][\theta][\alpha]{\rho\left(#1,#2\right)}
{\rho\left(#1;#2\right)}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\newcommand{\thetadom}{\Omega_{\theta}}
{\Omega_{\theta}}
\end_inset


\end_layout

\begin_layout Standard
\begin_inset FormulaMacro
\renewcommand{\thetadom}{\Omega_{\theta}}
{\Omega_{\theta}}
\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
A central question in many probabilistic clustering problems is how many
 distinct clusters are present in a particular dataset.
 In all but the simplest problems, any attempt to answer this question may
 be strongly determined by the criterion used.
 One common approach, based in the Bayesian tradition, addresses the problem
 with a generative model: out of a population of unobserved latent clusters,
 some finite number are randomly chosen to be present in the actual data
 at hand.
 The identity and number of these clusters can then be estimated – with
 attendant uncertainty estimates – using the tools of Bayesian posterior
 inference.
 For example, one might estimate the 
\begin_inset Quotes eld
\end_inset

number of distinct clusters present
\begin_inset Quotes erd
\end_inset

 by its posterior expectation.
 Such a generative model is called a 
\begin_inset Quotes eld
\end_inset

Bayesian non-parametric
\begin_inset Quotes erd
\end_inset

 (BNP) model when the number of latent clusters is infinite, though, naturally,
 even in non-parametric models only a finite number of clusters can actually
 be observed in any particular dataset.
 
\end_layout

\begin_layout Standard
As with any Bayesian model, this approach requires the specification of
 a prior and a likelihood.
 In this case, the likelihood describes the dispersion of data within a
 particular cluster, and the prior determines both the distribution of cluster
 shapes and sizes as well as the process that determines how many clusters
 are present.
 In general, different choices of the prior and likelihood would give different
 answers to the question 
\begin_inset Quotes eld
\end_inset

how many distinct clusters are present?
\begin_inset Quotes erd
\end_inset

 For example, if the prior does not somehow prefer fewer, larger clusters,
 then there is nothing that inherently prevents such an approach from inferring
 that each datapoint is in its own cluster.
 However, one still hopes that a broad range of reasonable choices of prior
 and likelihood will come to similar conclusions.
 Consequently, it is important, in practice, to measure the sensitivity
 of the inferred number of clusters present to the prior and likelihood
 specification.
 Furthermore, these sensitivity measures should work with the kinds of inference
 tools that are used in practice, operate relatively automatically without
 re-fitting the model many times, and measure sensitivity not only to alternativ
e hyperparameters but also to alternative functional forms of the prior
 and likelihood.
 
\end_layout

\begin_layout Standard
To address these needs, we develop fast, automatic measures of the sensitivity
 of variational Bayes (VB) approximations to perturbations of functional
 forms in a putative model.
 As a motivating application, we apply our techniques to estimate the sensitivit
y of BNP posteriors to the functional form of a particular BNP prior known
 as the stick-breaking prior.
 As we will see below, stick-breaking priors provide a strong motivation
 to quantify functional perturbations.
 A typical choice of a stick breaking prior is specified with only a single
 real-valued hyperparameter and also a potentially informative distributional
 assumption, the form of a stick breaking prior can substantially inform
 the number of clusters inferred to be present in a particular dataset,
 and it is arguably difficult for ordinary practitioners to form meaningful
 subjective beliefs about the abstract form of the stick breaking prior.
\end_layout

\begin_layout Standard
We begin by deriving a general result for the sensitivity of VB optima to
 function-valued perturbations, as well as several useful specializations.
 We then describe a VB approximation to a BNP model with a stick-breaking
 prior and derive the sensitivity of the approximate number of inferred
 clusters to the choice of the stick breaking prior.
 We then apply our methods to a real dataset, comparing our results to the
 much more expensive process of re-fitting the model.
\end_layout

\begin_layout Section
Parametric Sensitivity for Variational Bayes
\end_layout

\begin_layout Standard
Suppose we observe data, 
\begin_inset Formula $X$
\end_inset

, and a parameter 
\begin_inset Formula $\theta\in\thetadom\subseteq\mathbb{R}^{K}$
\end_inset

, which parameterizes a generative model for 
\begin_inset Formula $X$
\end_inset

, denoted 
\begin_inset Formula $p\left(X\vert\theta\right)$
\end_inset

.
 Here, 
\begin_inset Formula $K$
\end_inset

 may be finite or, as in the case of BNP, countably infinite.
 Defining a base prior, 
\begin_inset Formula $\baseprior$
\end_inset

, with respect to a dominating measure 
\begin_inset Formula $\lambda$
\end_inset

 on 
\begin_inset Formula $\thetadom$
\end_inset

, we can calculate the posterior distribution on 
\begin_inset Formula $\theta$
\end_inset

 given 
\begin_inset Formula $X$
\end_inset

:
\begin_inset Formula 
\begin{align*}
\basepost & :=\frac{p\left(X\vert\theta\right)\baseprior}{\int p\left(X\vert\theta'\right)\baseprior[\theta']\lambda\left(d\theta'\right)}.
\end{align*}

\end_inset

In many cases (such as BNP problems), 
\begin_inset Formula $\basepost$
\end_inset

 is intractable and must be approximated.
 One popular approximation technique, known as variational Bayes (VB), approxima
tes 
\begin_inset Formula $\basepost$
\end_inset

 in KL divergence within some class of tractable distributions.
 Define the 
\end_layout

\end_body
\end_document
