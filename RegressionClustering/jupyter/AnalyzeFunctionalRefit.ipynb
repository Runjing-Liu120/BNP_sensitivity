{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import inspect\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import paragami\n",
    "import vittles\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import bnpregcluster_runjingdev.regression_mixture_lib as gmm_lib\n",
    "import bnpregcluster_runjingdev.posterior_quantities_lib as post_lib\n",
    "\n",
    "np.random.seed(42) # nothing special about this seed (we hope)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "args = Args()\n",
    "args.fit_directory = '/home/rgiordan/Documents/git_repos/BNP_sensitivity/RegressionClustering/fits/cluster'\n",
    "args.refit_filename = os.path.join(fit_dir,\n",
    "    'transformed_gene_regression_df4_degree3_genes700_' +\n",
    "    'num_components40_inflate0.0_shrunkTrue_alphascale0.001_' +\n",
    "    'functionalTrue_logphiexpit_refit.npz')\n",
    "\n",
    "def set_directory(filename):\n",
    "    # If the fit_directory argument is set, replace a datafile's directory\n",
    "    # with the specified fit_directory and return the new location.\n",
    "    if args.fit_directory is None:\n",
    "        return filename\n",
    "    else:\n",
    "        _, file_only_name = os.path.split(filename)\n",
    "        return os.path.join(args.fit_directory, file_only_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'epsilon is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-73f2c110fe0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         infile['reopt_prior_params_flat'], free=False)\n\u001b[1;32m     11\u001b[0m     \u001b[0mreopt_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reopt_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0malpha_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epsilon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_fitfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git_repos/BNP_sensitivity/RegressionClustering/venv/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not a file in the archive\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'epsilon is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "with np.load(args.refit_filename) as infile:\n",
    "    initial_fitfile = set_directory(str(infile['input_filename']))\n",
    "    gmm_params_pattern = paragami.get_pattern_from_json(\n",
    "        str(infile['gmm_params_pattern_json']))\n",
    "    reopt_gmm_params = gmm_params_pattern.fold(\n",
    "        infile['reopt_gmm_params_flat'], free=False)\n",
    "    prior_params_pattern = paragami.get_pattern_from_json(\n",
    "        str(infile['reopt_prior_params_pattern_json']))\n",
    "    reopt_prior_params = prior_params_pattern.fold(\n",
    "        infile['reopt_prior_params_flat'], free=False)\n",
    "    reopt_time = infile['reopt_time']\n",
    "    alpha_scale = infile['alpha_scale']\n",
    "\n",
    "if not os.path.isfile(initial_fitfile):\n",
    "    raise ValueError('Initial fit {} not found'.format(initial_fitfile))\n",
    "\n",
    "with np.load(initial_fitfile) as infile:\n",
    "    gmm_params_pattern = paragami.get_pattern_from_json(\n",
    "        str(infile['gmm_params_pattern_json']))\n",
    "    opt_gmm_params = gmm_params_pattern.fold(\n",
    "        infile['opt_gmm_params_flat'], free=False)\n",
    "    prior_params_pattern = paragami.get_pattern_from_json(\n",
    "        str(infile['prior_params_pattern_json']))\n",
    "    prior_params = prior_params_pattern.fold(\n",
    "        infile['prior_params_flat'], free=False)\n",
    "    kl_hess = infile['kl_hess']\n",
    "    df = infile['df']\n",
    "    degree = infile['degree']\n",
    "    datafile = set_directory(str(infile['datafile']))\n",
    "    num_components = int(infile['num_components'])\n",
    "\n",
    "if not os.path.isfile(datafile):\n",
    "    raise ValueError('Datafile {} not found'.format(datafile))\n",
    "\n",
    "reg_params = dict()\n",
    "with np.load(datafile) as infile:\n",
    "    reg_params['beta_mean'] = infile['transformed_beta_mean']\n",
    "    reg_params['beta_info'] = infile['transformed_beta_info']\n",
    "    inflate_cov = infile.get('inflate_cov', 0)\n",
    "    eb_shrunk = infile.get('eb_shrunk', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.30235930567201"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 10000\n",
    "threshold = 2\n",
    "predictive = True\n",
    "\n",
    "get_posterior_quantity = post_lib.get_posterior_quantity_function(predictive, gmm, n_samples, threshold)\n",
    "\n",
    "get_posterior_quantity(opt_gmm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-44979.906553835244"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_free = False\n",
    "\n",
    "get_kl_from_vb_free_prior_free = \\\n",
    "    paragami.FlattenFunctionInput(original_fun=\n",
    "        gmm.get_params_prior_kl,\n",
    "        patterns = [gmm.gmm_params_pattern, prior_params_pattern],\n",
    "        free = [True, prior_free],\n",
    "        argnums = [0, 1])\n",
    "\n",
    "gmm.get_params_prior_kl(opt_gmm_params, prior_params)\n",
    "\n",
    "get_kl_from_vb_free_prior_free(\n",
    "    gmm.gmm_params_pattern.flatten(opt_gmm_params, free=True),\n",
    "    prior_params_pattern.flatten(prior_params, free=prior_free))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear response Hessian time: 0.006 secs\n"
     ]
    }
   ],
   "source": [
    "taylor_order = 1\n",
    "t0 = time.time()\n",
    "vb_sens = \\\n",
    "    vittles.ParametricSensitivityTaylorExpansion(\n",
    "        objective_function =    get_kl_from_vb_free_prior_free,\n",
    "        input_val0 =            gmm.gmm_params_pattern.flatten(opt_gmm_params, free=True),\n",
    "        hyper_val0 =            prior_params_pattern.flatten(prior_params, free=prior_free),\n",
    "        order =                 taylor_order,\n",
    "        hess0 =                 kl_hess)\n",
    "print('linear response Hessian time: {:.03f} secs'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig e: \t37.30235930567201\n",
      "Refit e:\t37.245883077931204\n",
      "Pred e:\t\t37.26632370093731\n",
      "Actual diff:\t-0.056476\n",
      "Pred diff:\t-0.036036\n"
     ]
    }
   ],
   "source": [
    "predict_gmm_params = \\\n",
    "    paragami.FoldFunctionInputAndOutput(\n",
    "        original_fun=vb_sens.evaluate_taylor_series,\n",
    "        input_patterns=prior_params_pattern,\n",
    "        input_free=prior_free,\n",
    "        input_argnums=[0],\n",
    "        output_patterns=gmm.gmm_params_pattern,\n",
    "        output_free=True,\n",
    "        output_retnums=[0])\n",
    "\n",
    "lr_time = time.time()\n",
    "pred_gmm_params = predict_gmm_params(reopt_prior_params)\n",
    "lr_time = lr_time - time.time()\n",
    "\n",
    "e_num0 = get_posterior_quantity(opt_gmm_params)\n",
    "e_num1 = get_posterior_quantity(reopt_gmm_params)\n",
    "e_num_pred = get_posterior_quantity(pred_gmm_params)\n",
    "\n",
    "print('Orig e: \\t{}\\nRefit e:\\t{}\\nPred e:\\t\\t{}\\nActual diff:\\t{:0.5}\\nPred diff:\\t{:0.5}'.format(\n",
    "    e_num0, e_num1, e_num_pred,\n",
    "    e_num1 - e_num0,\n",
    "    e_num_pred - e_num0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just testing\n",
    "\n",
    "import json_tricks\n",
    "\n",
    "save_dict = \\\n",
    "  [  { 'n_samples': n_samples,\n",
    "      'threshold': threshold,\n",
    "      'predictive': predictive,\n",
    "      'taylor_order': taylor_order,\n",
    "      'alpha1': new_alpha,\n",
    "      'alpha0': orig_alpha,\n",
    "      'e_num0': e_num0,\n",
    "      'e_num1': e_num1,\n",
    "      'e_num_pred': e_num_pred,\n",
    "      'lr_time': lr_time,\n",
    "      'refit_time': reopt_time } ]\n",
    "\n",
    "with open('/tmp/check.json', 'w') as outfile:\n",
    "    outfile.write(json_tricks.dumps(save_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with open('/tmp/check.json', 'r') as infile:\n",
    "    foo = json_tricks.loads(infile.read())\n",
    "    \n",
    "foo[0]['n_samples']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnpgmm_runjingdev",
   "language": "python",
   "name": "bnpgmm_runjingdev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
