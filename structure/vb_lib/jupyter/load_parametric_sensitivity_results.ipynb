{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/grad/runjing_liu/.conda/envs/bnp_sensitivity_jax/lib/python3.8/site-packages/jax/lib/xla_bridge.py:130: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "import jax.numpy as np\n",
    "import jax.scipy as sp\n",
    "\n",
    "import numpy as onp\n",
    "from numpy.polynomial.hermite import hermgauss\n",
    "\n",
    "import scipy as osp\n",
    "\n",
    "from vb_lib import structure_model_lib, data_utils, plotting_utils\n",
    "from vb_lib.preconditioner_lib import get_mfvb_cov_matmul\n",
    "from bnpmodeling_runjingdev.sensitivity_lib import HyperparameterSensitivityLinearApproximation\n",
    "\n",
    "import paragami\n",
    "\n",
    "import time\n",
    "from copy import deepcopy \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "from bnpmodeling_runjingdev import cluster_quantities_lib, modeling_lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_file = '../../../../fastStructure/test/testdata.npz'\n",
    "\n",
    "# data_file = '../../../../fastStructure/hgdp_data/huang2011_plink_files/' + \\\n",
    "#                 'phased_HGDP+India+Africa_2810SNPs-regions1to36.npz'\n",
    "\n",
    "data_file = '../data/huang2011_subsampled.npz'\n",
    "data = np.load(data_file)\n",
    "g_obs = np.array(data['g_obs'], dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs = g_obs.shape[0]\n",
    "n_loci = g_obs.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "print(n_obs)\n",
    "print(n_loci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_dir = '../fits/fits_20201112/'\n",
    "filenames = 'huang2011_sub_fit_alpha*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(fits_dir) if re.match(filenames, f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['huang2011_sub_fit_alpha10.0.npz',\n",
       " 'huang2011_sub_fit_alpha1.0.npz',\n",
       " 'huang2011_sub_fit_alpha4.5.npz',\n",
       " 'huang2011_sub_fit_alpha8.5.npz',\n",
       " 'huang2011_sub_fit_alpha11.0.npz',\n",
       " 'huang2011_sub_fit_alpha5.5.npz',\n",
       " 'huang2011_sub_fit_alpha9.5.npz',\n",
       " 'huang2011_sub_fit_alpha3.0.npz',\n",
       " 'huang2011_sub_fit_alpha6.5.npz',\n",
       " 'huang2011_sub_fit_alpha2.0.npz',\n",
       " 'huang2011_sub_fit_alpha7.5.npz',\n",
       " 'huang2011_sub_fit_alpha9.0.npz',\n",
       " 'huang2011_sub_fit_alpha5.0.npz',\n",
       " 'huang2011_sub_fit_alpha8.0.npz',\n",
       " 'huang2011_sub_fit_alpha4.0.npz',\n",
       " 'huang2011_sub_fit_alpha10.5.npz',\n",
       " 'huang2011_sub_fit_alpha1.5.npz',\n",
       " 'huang2011_sub_fit_alpha7.0.npz',\n",
       " 'huang2011_sub_fit_alpha2.5.npz',\n",
       " 'huang2011_sub_fit_alpha6.0.npz',\n",
       " 'huang2011_sub_fit_alpha3.5.npz']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load first fit to get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, vb_params_paragami, meta_data = \\\n",
    "    paragami.load_folded(fits_dir + files[0])\n",
    "\n",
    "# logitnormal parameters\n",
    "gh_deg = int(meta_data['gh_deg'])\n",
    "gh_loc, gh_weights = hermgauss(gh_deg)\n",
    "\n",
    "gh_loc = np.array(gh_loc)\n",
    "gh_weights = np.array(gh_weights)\n",
    "\n",
    "# prior parameters for population beta\n",
    "prior_params_dict, prior_params_paragami = \\\n",
    "    structure_model_lib.get_default_prior_params()\n",
    "\n",
    "prior_params_dict['allele_prior_alpha'] = np.array(meta_data['allele_prior_alpha'])\n",
    "prior_params_dict['allele_prior_beta'] = np.array(meta_data['allele_prior_beta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading fit from:  huang2011_sub_fit_alpha10.0.npz\n",
      "loading fit from:  huang2011_sub_fit_alpha1.0.npz\n",
      "loading fit from:  huang2011_sub_fit_alpha4.5.npz\n",
      "loading fit from:  huang2011_sub_fit_alpha8.5.npz\n",
      "loading fit from:  huang2011_sub_fit_alpha11.0.npz\n",
      "loading fit from:  huang2011_sub_fit_alpha5.5.npz\n",
      "loading fit from:  huang2011_sub_fit_alpha9.5.npz\n",
      "loading fit from:  huang2011_sub_fit_alpha3.0.npz\n",
      "loading fit from:  huang2011_sub_fit_alpha6.5.npz\n",
      "loading fit from:  huang2011_sub_fit_alpha2.0.npz\n",
      "loading fit from:  huang2011_sub_fit_alpha7.5.npz\n",
      "loading fit from:  huang2011_sub_fit_alpha9.0.npz\n",
      "loading fit from:  huang2011_sub_fit_alpha5.0.npz\n",
      "loading fit from:  huang2011_sub_fit_alpha8.0.npz\n",
      "loading fit from:  huang2011_sub_fit_alpha4.0.npz\n",
      "loading fit from:  huang2011_sub_fit_alpha10.5.npz\n",
      "loading fit from:  huang2011_sub_fit_alpha1.5.npz\n",
      "loading fit from:  huang2011_sub_fit_alpha7.0.npz\n",
      "loading fit from:  huang2011_sub_fit_alpha2.5.npz\n",
      "loading fit from:  huang2011_sub_fit_alpha6.0.npz\n",
      "loading fit from:  huang2011_sub_fit_alpha3.5.npz\n"
     ]
    }
   ],
   "source": [
    "vb_refit_list = []\n",
    "alpha_vec = onp.zeros(len(files))\n",
    "\n",
    "for i in range(len(files)): \n",
    "    \n",
    "    print('loading fit from: ', files[i])\n",
    "    \n",
    "    # load fit\n",
    "    vb_params_dict, vb_params_paragami, meta_data = \\\n",
    "        paragami.load_folded(fits_dir + files[i])\n",
    "    \n",
    "    # check KL\n",
    "    prior_params_dict['dp_prior_alpha'] = np.array(meta_data['dp_prior_alpha'])\n",
    "    \n",
    "    kl = structure_model_lib.get_kl(g_obs, vb_params_dict, prior_params_dict,\n",
    "                                gh_loc, gh_weights)\n",
    "    \n",
    "    assert np.abs(kl - meta_data['final_kl']) < 1e-8\n",
    "    \n",
    "    # save alpha and fitted parametrs\n",
    "    alpha_vec[i] = meta_data['dp_prior_alpha']\n",
    "    vb_refit_list.append(vb_params_paragami.flatten(vb_params_dict, free = True))\n",
    "    \n",
    "alpha_vec = np.array(alpha_vec)\n",
    "vb_refit_list = np.array(vb_refit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for convencience, sort the alphas \n",
    "_indx = np.argsort(alpha_vec)\n",
    "alpha_vec = alpha_vec[_indx]\n",
    "vb_refit_list = vb_refit_list[_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([ 1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5,  5. ,  5.5,\n",
       "              6. ,  6.5,  7. ,  7.5,  8. ,  8.5,  9. ,  9.5, 10. , 10.5,\n",
       "             11. ], dtype=float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(True, dtype=bool)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no gaps \n",
    "np.all(np.diff(alpha_vec) == 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the initial fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5\n"
     ]
    }
   ],
   "source": [
    "indx0 = 5\n",
    "\n",
    "alpha0 = alpha_vec[indx0]\n",
    "print(alpha0)\n",
    "\n",
    "vb_opt = vb_refit_list[indx0]\n",
    "vb_opt_dict = vb_params_paragami.fold(vb_refit_list[indx0], free = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot initial fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "e_ind_admix = plotting_utils.get_vb_expectations(vb_params_dict, gh_loc, gh_weights)[0]\n",
    "# re-order individuals for better plotting\n",
    "indx = data_utils.cluster_admix_get_indx(e_ind_admix)\n",
    "\n",
    "f, axarr = plt.subplots(1, 1, figsize=(6, 3))\n",
    "e_ind_admix = plotting_utils.plot_top_clusters(e_ind_admix[indx], axarr, \n",
    "                                               n_top_clusters = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expected number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2342\n",
    "key = jax.random.PRNGKey(seed)\n",
    "\n",
    "@jax.jit\n",
    "def get_e_num_clusters(vb_params_dict): \n",
    "    # TODO this is super slow ...\n",
    "    # return 0.\n",
    "    return structure_model_lib.get_e_num_clusters(g_obs, vb_params_dict, gh_loc, gh_weights, \n",
    "                                                   n_samples = 1000,\n",
    "                                                   threshold = 0,\n",
    "                                                   seed = seed)\n",
    "\n",
    "@jax.jit\n",
    "def get_e_num_pred_clusters(vb_params_dict): \n",
    "    \n",
    "    stick_means = vb_params_dict['ind_admix_params']['stick_means']\n",
    "    stick_infos = vb_params_dict['ind_admix_params']['stick_infos']\n",
    "    \n",
    "    return structure_model_lib.get_e_num_pred_clusters(stick_means, stick_infos, gh_loc, gh_weights, \n",
    "                                                            key = key, n_samples = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(22.09, dtype=float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_e_num_clusters(vb_opt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(4.15290645, dtype=float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_e_num_pred_clusters(vb_opt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define sensitivity object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial prior alpha\n",
    "use_free_alpha = True\n",
    "prior_alpha0 = prior_params_paragami['dp_prior_alpha'].flatten(alpha0, \n",
    "                                                              free = use_free_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up objective as function of vb params and prior param \n",
    "\n",
    "def objective_fun(vb_params_dict, alpha): \n",
    "    \n",
    "    _prior_params_dict = deepcopy(prior_params_dict)\n",
    "    _prior_params_dict['dp_prior_alpha'] = alpha\n",
    "    \n",
    "    return structure_model_lib.get_kl(g_obs, vb_params_dict, _prior_params_dict,\n",
    "                    gh_loc = gh_loc, gh_weights = gh_weights)\n",
    "\n",
    "\n",
    "objective_fun_free = paragami.FlattenFunctionInput(\n",
    "                                original_fun=objective_fun, \n",
    "                                patterns = [vb_params_paragami, prior_params_paragami['dp_prior_alpha']],\n",
    "                                free = [True, use_free_alpha],\n",
    "                                argnums = [0, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get hessian solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define preconditioner\n",
    "cg_precond = lambda v : get_mfvb_cov_matmul(v, vb_opt_dict,\n",
    "                                            vb_params_paragami,\n",
    "                                            return_sqrt = False, \n",
    "                                            return_info = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute VB sensitivity derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling ...\n",
      "Compile time: 165.013sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vb_sens = HyperparameterSensitivityLinearApproximation(objective_fun_free,\n",
    "                                                        vb_opt,\n",
    "                                                        prior_alpha0, \n",
    "                                                        cg_precond=cg_precond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get linear reponse predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_clusters_vec(vb_free_params_list, cluster_fun): \n",
    "    # vb_free_params_list contains an array of \n",
    "    # vb free parameters, where each row contains \n",
    "    # parameters from a different refit (or lr prediction)\n",
    "    \n",
    "    # cluster fun takes input a vb parameter dictionary \n",
    "    # and returns the posterior expectation of interest\n",
    "    \n",
    "    n_refit = len(vb_free_params_list)\n",
    "    n_clusters_vec = onp.zeros(n_refit)\n",
    "    \n",
    "    for i in range(n_refit): \n",
    "        print(i)\n",
    "        # fold \n",
    "        vb_dict = vb_params_paragami.fold(vb_free_params_list[i], \n",
    "                                          free = True)\n",
    "\n",
    "        # get number of clusters\n",
    "        n_clusters_vec[i] = cluster_fun(vb_dict)\n",
    "    \n",
    "    return n_clusters_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_predictions(vb_sens): \n",
    "\n",
    "    t0 = time.time()\n",
    "    lr_free_params_list = []\n",
    "    for i in range(len(alpha_vec)): \n",
    "    \n",
    "        # get lr predicted parameters\n",
    "        alpha_pert = prior_params_paragami['dp_prior_alpha'].flatten(alpha_vec[i],\n",
    "                                                                     free = use_free_alpha)\n",
    "\n",
    "        lr_free = vb_sens.predict_opt_par_from_hyper_par(alpha_pert)\n",
    "        \n",
    "        lr_free_params_list.append(lr_free)\n",
    "    \n",
    "    # computing the vb parameters are fast!\n",
    "    print('lr time: {:03f}secs'.format(time.time() - t0))\n",
    "    \n",
    "    # actually computing the posterior quantity can be slow\n",
    "    return lr_free_params_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr time: 0.127323secs\n"
     ]
    }
   ],
   "source": [
    "lr_free_params_list = get_lr_predictions(vb_sens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "lr_n_clusters_vec = get_num_clusters_vec(lr_free_params_list, get_e_num_clusters)\n",
    "lr_n_pred_clusters_vec = get_num_clusters_vec(lr_free_params_list, get_e_num_pred_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare against refit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refit_n_clusters_vec = get_num_clusters_vec(vb_refit_list, get_e_num_clusters)\n",
    "refit_n_pred_clusters_vec = get_num_clusters_vec(vb_refit_list, get_e_num_pred_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 2, figsize = (10, 4))\n",
    "\n",
    "# plot in-sample results\n",
    "axarr[0].plot(alpha_vec, lr_n_clusters_vec, '+--')\n",
    "axarr[0].plot(alpha_vec, refit_n_clusters_vec, '+-')\n",
    "\n",
    "axarr[0].set_xlabel('alpha')\n",
    "axarr[0].set_ylabel('num posterior clusters')\n",
    "axarr[0].legend(('lr', 'refit'))\n",
    "\n",
    "# plot posterior-predictive results\n",
    "axarr[1].plot(alpha_vec, lr_n_pred_clusters_vec, '+--')\n",
    "axarr[1].plot(alpha_vec, refit_n_pred_clusters_vec, '+-')\n",
    "\n",
    "axarr[1].set_xlabel('alpha')\n",
    "axarr[1].set_ylabel('num posterior pred clusters')\n",
    "\n",
    "plt.axvline(alpha0, color = 'red', linestyle = 'dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start from a different alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx0 = 10\n",
    "\n",
    "alpha1 = alpha_vec[indx0]\n",
    "print(alpha1)\n",
    "\n",
    "vb_opt = vb_refit_list[indx0]\n",
    "vb_opt_dict = vb_params_paragami.fold(vb_refit_list[indx0], free = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1, 1, figsize=(6, 3))\n",
    "e_ind_admix = plotting_utils.get_vb_expectations(vb_opt_dict, gh_loc, gh_weights)[0]\n",
    "e_ind_admix = plotting_utils.plot_top_clusters(e_ind_admix[indx], axarr, \n",
    "                                               n_top_clusters = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reset sensitivity derivatives \n",
    "\n",
    "t0 = time.time()\n",
    "vb_sens.set_derivatives(vb_opt, \n",
    "                        prior_params_paragami['dp_prior_alpha'].flatten(alpha1, \n",
    "                                                              free = use_free_alpha))\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new predictions\n",
    "lr_free_params_list1 = get_lr_predictions(vb_sens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_n_clusters_vec1 = get_num_clusters_vec(lr_free_params_list1, get_e_num_clusters)\n",
    "lr_n_pred_clusters_vec1 = get_num_clusters_vec(lr_free_params_list1, get_e_num_pred_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 2, figsize = (10, 4))\n",
    "\n",
    "# plot in-sample results\n",
    "axarr[0].plot(alpha_vec, lr_n_clusters_vec1, '+--')\n",
    "axarr[0].plot(alpha_vec, refit_n_clusters_vec, '+-')\n",
    "\n",
    "axarr[0].set_xlabel('alpha')\n",
    "axarr[0].set_ylabel('num posterior clusters')\n",
    "axarr[0].legend(('lr', 'refit'))\n",
    "\n",
    "# plot posterior-predictive results\n",
    "axarr[1].plot(alpha_vec, lr_n_pred_clusters_vec1, '+--')\n",
    "axarr[1].plot(alpha_vec, refit_n_pred_clusters_vec, '+-')\n",
    "\n",
    "axarr[1].set_xlabel('alpha')\n",
    "axarr[1].set_ylabel('num posterior pred clusters')\n",
    "\n",
    "plt.axvline(alpha1, color = 'red', linestyle = 'dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start from a different alpha (again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx0 = 17\n",
    "\n",
    "alpha2 = alpha_vec[indx0]\n",
    "print(alpha2)\n",
    "\n",
    "vb_opt = vb_refit_list[indx0]\n",
    "vb_opt_dict = vb_params_paragami.fold(vb_refit_list[indx0], free = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1, 1, figsize=(6, 3))\n",
    "e_ind_admix = plotting_utils.get_vb_expectations(vb_opt_dict, gh_loc, gh_weights)[0]\n",
    "e_ind_admix = plotting_utils.plot_top_clusters(e_ind_admix[indx], axarr, \n",
    "                                               n_top_clusters = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reset sensitivity derivatives \n",
    "\n",
    "t0 = time.time()\n",
    "vb_sens.set_derivatives(vb_opt, \n",
    "                        prior_params_paragami['dp_prior_alpha'].flatten(alpha2, \n",
    "                                                              free = use_free_alpha))\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new predictions\n",
    "lr_free_params_list2 = get_lr_predictions(vb_sens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_n_clusters_vec2 = get_num_clusters_vec(lr_free_params_list2, get_e_num_clusters)\n",
    "lr_n_pred_clusters_vec2 = get_num_clusters_vec(lr_free_params_list2, get_e_num_pred_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 2, figsize = (10, 4))\n",
    "\n",
    "# plot in-sample results\n",
    "axarr[0].plot(alpha_vec, lr_n_clusters_vec2, '+--')\n",
    "axarr[0].plot(alpha_vec, refit_n_clusters_vec, '+-')\n",
    "\n",
    "axarr[0].set_xlabel('alpha')\n",
    "axarr[0].set_ylabel('num posterior clusters')\n",
    "axarr[0].legend(('lr', 'refit'))\n",
    "\n",
    "# plot posterior-predictive results\n",
    "axarr[1].plot(alpha_vec, lr_n_pred_clusters_vec2, '+--')\n",
    "axarr[1].plot(alpha_vec, refit_n_pred_clusters_vec, '+-')\n",
    "\n",
    "axarr[1].set_xlabel('alpha')\n",
    "axarr[1].set_ylabel('num posterior pred clusters')\n",
    "\n",
    "plt.axvline(alpha2, color = 'red', linestyle = 'dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the final plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 3, figsize = (15, 4))\n",
    "\n",
    "for i in range(3): \n",
    "    axarr[i].plot(alpha_vec, refit_n_clusters_vec, '+-', label = 'refit')\n",
    "    axarr[i].set_xlabel('alpha')\n",
    "    axarr[i].set_ylabel('num clusters')\n",
    "\n",
    "    \n",
    "axarr[0].plot(alpha_vec, lr_n_clusters_vec, '+--')\n",
    "axarr[0].axvline(alpha0, color = 'red')\n",
    "\n",
    "axarr[1].plot(alpha_vec, lr_n_clusters_vec1, '+--')\n",
    "axarr[1].axvline(alpha1, color = 'red')\n",
    "\n",
    "axarr[2].plot(alpha_vec, lr_n_clusters_vec2, '+--', label = 'lr')\n",
    "axarr[2].axvline(alpha2, color = 'red')\n",
    "\n",
    "axarr[2].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 3, figsize = (15, 4))\n",
    "\n",
    "for i in range(3): \n",
    "    axarr[i].plot(alpha_vec, refit_n_pred_clusters_vec, '+-', label = 'refit')\n",
    "    axarr[i].set_xlabel('alpha')\n",
    "    axarr[i].set_ylabel('num clusters')\n",
    "\n",
    "    \n",
    "axarr[0].plot(alpha_vec, lr_n_pred_clusters_vec, '+--')\n",
    "axarr[0].axvline(alpha0, color = 'red')\n",
    "\n",
    "axarr[1].plot(alpha_vec, lr_n_pred_clusters_vec1, '+--')\n",
    "axarr[1].axvline(alpha1, color = 'red')\n",
    "\n",
    "axarr[2].plot(alpha_vec, lr_n_pred_clusters_vec2, '+--', label = 'lr')\n",
    "axarr[2].axvline(alpha2, color = 'red')\n",
    "\n",
    "axarr[2].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def sample_ez(e_z, n_samples, seed): \n",
    "    # e_z is of shape n x k\n",
    "    # index (n,k) is probability of n-th observation \n",
    "    # belonging to cluster k\n",
    "    \n",
    "    logits = np.log(e_z)\n",
    "    \n",
    "    \n",
    "    z_samples = jax.random.categorical(key = jax.random.PRNGKey(seed), \n",
    "                               logits = logits, \n",
    "                               shape = (n_samples, e_z.shape[0]))\n",
    "    \n",
    "    # shape is n_samples x n x k\n",
    "    return jax.nn.one_hot(z_samples, num_classes = e_z.shape[1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from jax.experimental import loops"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def e_num_clusters_from_ez(g_obs, vb_params_dict, gh_loc, gh_weights, \n",
    "                           n_samples, threshold = 0,\n",
    "                           seed = 342): \n",
    "    \n",
    "    e_log_sticks, e_log_1m_sticks, \\\n",
    "        e_log_pop_freq, e_log_1m_pop_freq = \\\n",
    "            structure_model_lib.get_moments_from_vb_params_dict(vb_params_dict,\n",
    "                                    gh_loc = gh_loc,\n",
    "                                    gh_weights = gh_weights)\n",
    "    e_log_cluster_probs = \\\n",
    "        modeling_lib.get_e_log_cluster_probabilities_from_e_log_stick(\n",
    "                            e_log_sticks, e_log_1m_sticks)\n",
    "    \n",
    "    n_obs = g_obs.shape[0]\n",
    "    k_approx = e_log_cluster_probs.shape[-1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    with loops.Scope() as s:\n",
    "        s.sampled_counts = np.zeros((n_samples, k_approx))\n",
    "        \n",
    "        for l in s.range(g_obs.shape[1]):\n",
    "            # e_z_l is shaped as n_obs x k_approx x 2\n",
    "            _, e_z_l = structure_model_lib.get_optimal_ezl(g_obs[:, l],\n",
    "                                    e_log_pop_freq[l], e_log_1m_pop_freq[l],\n",
    "                                    e_log_cluster_probs)\n",
    "\n",
    "            # combine first and last dimension\n",
    "            e_z_l = e_z_l.transpose((0, 2, 1)).\\\n",
    "                            reshape((n_obs * 2, k_approx))\n",
    "\n",
    "            # sample counts\n",
    "            sampled_counts_l = sample_ez(e_z_l, n_samples, seed).sum(1)\n",
    "\n",
    "            s.sampled_counts += sampled_counts_l\n",
    "    \n",
    "    n_clusters_sampled = (s.sampled_counts > threshold).sum(1)\n",
    "    \n",
    "    return n_clusters_sampled.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading in an already saved hessian inverse solution ... \n",
    "\n",
    "# class VBSensitivity(object): \n",
    "#     def __init__(self, lr_file, opt_par_value, hyper_par_value0): \n",
    "#         self.dinput_dhyper = np.load(lr_file)\n",
    "        \n",
    "#         self.opt_par_value = opt_par_value\n",
    "#         self.hyper_par_value0 = hyper_par_value0\n",
    "        \n",
    "#     def predict_opt_par_from_hyper_par(self, hyper_par_value):\n",
    "#         delta = (hyper_par_value - self.hyper_par_value0)\n",
    "\n",
    "#         if len(self.dinput_dhyper.shape) == 1:\n",
    "#             self.dinput_dhyper = np.expand_dims(self.dinput_dhyper, 1)\n",
    "\n",
    "#         return np.dot(self.dinput_dhyper, delta) + self.opt_par_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_lr_der = True\n",
    "# if load_lr_der: \n",
    "#     lr_file = fit_dir + 'alpha_sens_nobs{}_nloci{}_npop{}_alpha{}.npy'.format(n_obs, \n",
    "#                                                                           n_loci, \n",
    "#                                                                           n_pop, \n",
    "#                                                                           alpha0)\n",
    "#     vb_sens = VBSensitivity(lr_file, vb_opt, prior_alpha0)\n",
    "# else: \n",
    "#     vb_sens = HyperparameterSensitivityLinearApproximation(objective_fun_free,\n",
    "#                                                         vb_opt,\n",
    "#                                                         prior_alpha0, \n",
    "#                                                         cg_precond=cg_precond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def e_num_clusters_from_ez(vb_params_dict, gh_loc, gh_weights): \n",
    "#     e_log_sticks, e_log_1m_sticks, \\\n",
    "#         e_log_pop_freq, e_log_1m_pop_freq = \\\n",
    "#             structure_model_lib.get_moments_from_vb_params_dict(vb_params_dict,\n",
    "#                                     gh_loc = gh_loc,\n",
    "#                                     gh_weights = gh_weights)\n",
    "#     e_log_cluster_probs = \\\n",
    "#         modeling_lib.get_e_log_cluster_probabilities_from_e_log_stick(\n",
    "#                             e_log_sticks, e_log_1m_sticks)\n",
    "    \n",
    "    \n",
    "#     prod_ez = 1.\n",
    "#     for l in range(g_obs.shape[1]):\n",
    "#         _, e_z_l = structure_model_lib.get_optimal_ezl(g_obs[:, l],\n",
    "#                                 e_log_pop_freq[l], e_log_1m_pop_freq[l],\n",
    "#                                 e_log_cluster_probs)\n",
    "        \n",
    "#         prod_ez *= (1 - e_z_l).prod(2).prod(0)\n",
    "                \n",
    "#     return prod_ez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnp_sensitivity_jax",
   "language": "python",
   "name": "bnp_sensitivity_jax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
