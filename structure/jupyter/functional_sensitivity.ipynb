{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we examine the sensitivity to a functional perturbation on a small simulated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bnpmodeling_runjingdev'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ad90a7abc2bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolynomial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhermite\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhermgauss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvb_lib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructure_model_lib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcavi_lib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplotting_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvb_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructure_optimization_lib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms_optim_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvb_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreconditioner_lib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_mfvb_cov_matmul\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git_repos/BNP_sensitivity/structure/vb_lib/structure_model_lib.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparagami\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mbnpmodeling_runjingdev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional_sensitivity_lib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfunc_sens_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbnpmodeling_runjingdev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexponential_families\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mef\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bnpmodeling_runjingdev'"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "import jax.numpy as np\n",
    "import jax.scipy as sp\n",
    "from numpy.polynomial.hermite import hermgauss\n",
    "\n",
    "from vb_lib import structure_model_lib, data_utils, cavi_lib, plotting_utils\n",
    "import vb_lib.structure_optimization_lib as s_optim_lib\n",
    "from vb_lib.preconditioner_lib import get_mfvb_cov_matmul\n",
    "\n",
    "import paragami\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "from bnpmodeling_runjingdev import influence_lib, modeling_lib, log_phi_lib\n",
    "from bnpmodeling_runjingdev.sensitivity_lib import HyperparameterSensitivityLinearApproximation\n",
    "import bnpmodeling_runjingdev.functional_sensitivity_lib as func_sens_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp \n",
    "onp.random.seed(53453)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs = 50\n",
    "n_loci = 200\n",
    "n_pop = 3\n",
    "g_obs, true_pop_allele_freq, true_ind_admix_propn = \\\n",
    "    data_utils.draw_data(n_obs, n_loci, n_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_params_dict, prior_params_paragami = \\\n",
    "    structure_model_lib.get_default_prior_params()\n",
    "\n",
    "print(prior_params_dict)\n",
    "\n",
    "prior_params_free = prior_params_paragami.flatten(prior_params_dict, free = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get VB params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_approx = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh_deg = 8\n",
    "gh_loc, gh_weights = hermgauss(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, vb_params_paragami = \\\n",
    "    structure_model_lib.get_vb_params_paragami_object(n_obs, n_loci, k_approx,\n",
    "                                                      use_logitnormal_sticks = True)\n",
    "    \n",
    "print(vb_params_paragami)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize with CAVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vb_params_dict, cavi_init_time = \\\n",
    "            s_optim_lib.initialize_with_cavi(g_obs, \n",
    "                                 vb_params_paragami, \n",
    "                                 prior_params_dict, \n",
    "                                 gh_loc, gh_weights, \n",
    "                                 print_every = 20, \n",
    "                                 max_iter = 200, \n",
    "                                 seed = 1232)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize with preconditioned LBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vb_opt_dict, vb_opt, out, precond_objective, lbfgs_time = \\\n",
    "    s_optim_lib.run_preconditioned_lbfgs(g_obs, \n",
    "                        vb_params_dict, \n",
    "                        vb_params_paragami,\n",
    "                        prior_params_dict,\n",
    "                        gh_loc, gh_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check out the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 2, figsize = (12, 4))\n",
    "\n",
    "###############\n",
    "# estimated \n",
    "###############\n",
    "e_ind_admix, e_pop_freq = plotting_utils.get_vb_expectations(vb_opt_dict, gh_loc, gh_weights)\n",
    "\n",
    "_, sorted_indx = \\\n",
    "    plotting_utils.plot_top_clusters(e_ind_admix, axarr[0], n_top_clusters = n_pop)\n",
    "axarr[0].set_title('estimated')\n",
    "\n",
    "e_pop_freq = e_pop_freq[:, sorted_indx]\n",
    "\n",
    "###############\n",
    "# truth \n",
    "###############\n",
    "# permute so that colors match (as well as possible)\n",
    "perm = data_utils.find_min_perm(true_pop_allele_freq, e_pop_freq, axis = 1)\n",
    "\n",
    "plotting_utils.plot_top_clusters(true_ind_admix_propn[:, perm], axarr[1], \n",
    "                                 n_top_clusters = n_pop);\n",
    "axarr[1].set_title('truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up linear response derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is just a place holder for a null perturbation\n",
    "# will set this properly later\n",
    "hyper_par_objective_fun = lambda params, epsilon: 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up linear approximation class\n",
    "epsilon0 = np.array([0.])\n",
    "\n",
    "epsilon_sens = \\\n",
    "    HyperparameterSensitivityLinearApproximation(\n",
    "        # doesnt matter bc we give it the hvp\n",
    "        # and we will give it the hyper_par objective later\n",
    "        objective_fun = None, \n",
    "        opt_par_value = vb_opt, \n",
    "        hyper_par_value0 = epsilon0, \n",
    "        obj_fun_hvp = precond_objective.hvp, \n",
    "        hyper_par_objective_fun = hyper_par_objective_fun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute influence function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define posterior quantity of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(vb_free_params, vb_params_paragami): \n",
    "    \n",
    "    # key for random sampling. \n",
    "    # this is fixed! so all standard normal \n",
    "    # samples used in computing the posterior quantity \n",
    "    key = jax.random.PRNGKey(0)\n",
    "    \n",
    "    vb_params_dict = vb_params_paragami.fold(vb_free_params, free = True)\n",
    "    \n",
    "    stick_means = vb_params_dict['ind_admix_params']['stick_means']\n",
    "    stick_infos = vb_params_dict['ind_admix_params']['stick_infos']\n",
    "    \n",
    "    return structure_model_lib.get_e_num_pred_clusters(stick_means, stick_infos, gh_loc, gh_weights, \n",
    "                                                       key = key,\n",
    "                                                       n_samples = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_grad_g = jax.jacobian(g, argnums = 0)\n",
    "grad_g = get_grad_g(vb_opt, vb_params_paragami)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the influence function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence_operator = influence_lib.InfluenceOperator(vb_opt, \n",
    "                           vb_params_paragami, \n",
    "                           epsilon_sens.hessian_solver,\n",
    "                           prior_params_dict['dp_prior_alpha'], \n",
    "                           stick_key = 'ind_admix_params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### worst-case perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_v_grid = np.linspace(-10, 10, 200)\n",
    "influence_grid = influence_operator.get_influence(logit_v_grid, grad_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_case_pert = influence_lib.WorstCasePerturbation(influence_fun = None, \n",
    "                                                      logit_v_grid = logit_v_grid, \n",
    "                                                      cached_influence_grid = influence_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot influence function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize = (15, 4)) \n",
    "\n",
    "ax[0].plot(worst_case_pert.logit_v_grid, np.sign(worst_case_pert.influence_grid))\n",
    "ax[0].set_xlabel('logit v')\n",
    "ax[0].set_ylabel('sign(Influence)')\n",
    "\n",
    "ax[1].plot(worst_case_pert.logit_v_grid, worst_case_pert.influence_grid)\n",
    "ax[1].set_xlabel('logit v')\n",
    "ax[1].set_ylabel('Influence')\n",
    "\n",
    "ax[2].plot(worst_case_pert.v_grid, worst_case_pert.influence_grid)\n",
    "ax[2].set_xlabel('v')\n",
    "ax[2].set_ylabel('Influence')\n",
    "\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define prior perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this contains a suite of perturbations\n",
    "f_obj_all = log_phi_lib.LogPhiPerturbations(vb_params_paragami, \n",
    "                                                 prior_params_dict['dp_prior_alpha'],\n",
    "                                                 gh_loc, \n",
    "                                                 gh_weights,\n",
    "                                                 logit_v_grid = logit_v_grid, \n",
    "                                                 influence_grid = influence_grid, \n",
    "                                                 stick_key = 'ind_admix_params')\n",
    "\n",
    "# name of the perturbation \n",
    "perturbation = 'worst_case'\n",
    "\n",
    "# get class containing the necessary methods\n",
    "f_obj = getattr(f_obj_all, 'f_obj_' + perturbation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_perturbation = func_sens_lib.PriorPerturbation(\n",
    "                                alpha0 = prior_params_dict['dp_prior_alpha'],\n",
    "                                log_phi = f_obj.log_phi, \n",
    "                                logit_v_ub = 10, \n",
    "                                logit_v_lb = -10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prior_perturbation.set_epsilon(1.0)\n",
    "\n",
    "v_grid = sp.special.expit(logit_v_grid)\n",
    "\n",
    "plt.figure(1, figsize=(18, 5))\n",
    "\n",
    "plt.subplot(141)\n",
    "plt.plot(logit_v_grid, prior_perturbation.get_log_p0_logit(logit_v_grid))\n",
    "plt.plot(logit_v_grid, prior_perturbation.get_log_pc_logit(logit_v_grid))\n",
    "plt.title('Log priors in logit space')\n",
    "\n",
    "plt.subplot(142)\n",
    "plt.plot(logit_v_grid, prior_perturbation.log_phi(logit_v_grid))\n",
    "plt.title('log phi in logit space')\n",
    "\n",
    "plt.subplot(143)\n",
    "plt.plot(v_grid, np.exp(prior_perturbation.get_log_p0(v_grid)))\n",
    "plt.plot(v_grid, np.exp(prior_perturbation.get_log_pc(v_grid)))\n",
    "plt.title('Priors in stick space')\n",
    "\n",
    "plt.subplot(144)\n",
    "plt.plot(logit_v_grid, np.exp(prior_perturbation.get_log_p0_logit(logit_v_grid)),\n",
    "            label = 'p0')\n",
    "plt.plot(logit_v_grid, np.exp(prior_perturbation.get_log_pc_logit(logit_v_grid)),\n",
    "            label = 'p1')\n",
    "plt.title('Priors in logit space')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get derivative for prior perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_sens._set_cross_hess_and_solve(f_obj.hyper_par_objective_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.1\n",
    "print('Epsilon: ', epsilon)\n",
    "\n",
    "lr_vb_free_params = epsilon_sens.predict_opt_par_from_hyper_par(epsilon)\n",
    "\n",
    "print('init number of cluster: ', g(vb_opt, vb_params_paragami))\n",
    "print('lr number of cluster: ', g(lr_vb_free_params, vb_params_paragami))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vb_pert_pred_dict = vb_params_paragami.fold(lr_vb_free_params, free = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_init_dict = deepcopy(vb_opt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vb_pert_dict, vb_opt_pert = \\\n",
    "    s_optim_lib.run_preconditioned_lbfgs(g_obs, \n",
    "                                            new_init_dict,\n",
    "                                            vb_params_paragami,\n",
    "                                            prior_params_dict,\n",
    "                                            gh_loc = gh_loc,\n",
    "                                            gh_weights = gh_weights,\n",
    "                                            e_log_phi = lambda means, infos : \\\n",
    "                                                           f_obj.e_log_phi_epsilon(means,\n",
    "                                                                                       infos,\n",
    "                                                                                       epsilon))[0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(vb_opt_pert - vb_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_diff_plot(lr_vb_free_params, vb_opt_pert, vb_opt): \n",
    "    plt.plot((lr_vb_free_params - vb_opt), \n",
    "             vb_opt_pert - vb_opt, \n",
    "             '+', color = 'red')\n",
    "\n",
    "    plt.plot(lr_vb_free_params - vb_opt, \n",
    "            lr_vb_free_params - vb_opt, \n",
    "             '-', color = 'blue')\n",
    "\n",
    "    plt.xlabel('lr')\n",
    "    plt.ylabel('re-optimized')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare free parameters\n",
    "print_diff_plot(lr_vb_free_params, vb_opt_pert, vb_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('init number of cluster: ', g(vb_opt, vb_params_paragami))\n",
    "print('pert number of cluster: ', g(vb_opt_pert, vb_params_paragami))\n",
    "print('lr number of cluster: ', g(lr_vb_free_params, vb_params_paragami))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit for a range of epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_list = np.linspace(0, 1, 8) ** 2 # Square to get more points close to 0\n",
    "print(epsilon_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refit_with_epsilon(epsilon, new_init_dict):\n",
    "    # sets new epsilon, returns new vb optimum\n",
    "    \n",
    "    vb_opt = s_optim_lib.run_preconditioned_lbfgs(g_obs, \n",
    "                                         new_init_dict,\n",
    "                                        vb_params_paragami,\n",
    "                                        prior_params_dict,\n",
    "                                        gh_loc = gh_loc,\n",
    "                                        gh_weights = gh_weights,\n",
    "                                        e_log_phi = lambda means, infos : \\\n",
    "                                                           f_obj.e_log_phi_epsilon(means, infos, epsilon))[1]\n",
    "        \n",
    "    return vb_opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('epsilons: ', epsilon_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vb_pert_list = []\n",
    "for epsilon in epsilon_list: \n",
    "    print('\\n re-optimzing with epsilon = ', epsilon)\n",
    "    \n",
    "    vb_pert_list.append(refit_with_epsilon(epsilon, new_init_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check free parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = []\n",
    "\n",
    "for epsilon in epsilon_list: \n",
    "    \n",
    "    # get linear response\n",
    "    lr_list.append(epsilon_sens.predict_opt_par_from_hyper_par(epsilon))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(epsilon_list)): \n",
    "    plt.figure()\n",
    "    print_diff_plot(lr_list[i], vb_pert_list[i], vb_opt)\n",
    "    \n",
    "    plt.title('epsilon = {}'.format(epsilon_list[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_e_num_clusters_vec = onp.zeros(len(epsilon_list))\n",
    "refit_e_num_clusters_vec = onp.zeros(len(epsilon_list))\n",
    "\n",
    "for i in range(len(epsilon_list)): \n",
    "        \n",
    "    # get number of clusters\n",
    "    refit_e_num_clusters_vec[i] = g(vb_pert_list[i], vb_params_paragami)\n",
    "    lr_e_num_clusters_vec[i] = g(lr_list[i], vb_params_paragami)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(epsilon_list, lr_e_num_clusters_vec, '+--')\n",
    "plt.plot(epsilon_list, refit_e_num_clusters_vec, '+-')\n",
    "\n",
    "plt.xlabel('epsilon')\n",
    "plt.ylabel('num posterior clusters')\n",
    "plt.legend(('lr', 'refit'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnp_sensitivity_jax",
   "language": "python",
   "name": "bnp_sensitivity_jax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
